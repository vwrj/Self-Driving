{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pdb\n",
    "from collections import OrderedDict\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import collections  as mc\n",
    "matplotlib.rcParams['figure.figsize'] = [6, 6]\n",
    "matplotlib.rcParams['figure.dpi'] = 200\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "from data_helper import UnlabeledDataset, LabeledDataset\n",
    "from helper import draw_box\n",
    "\n",
    "# random.seed(0)\n",
    "# np.random.seed(0)\n",
    "# torch.manual_seed(0);\n",
    "\n",
    "# All the images are saved in image_folder\n",
    "# All the labels are saved in the annotation_csv file\n",
    "image_folder = '/scratch/brs426/data'\n",
    "annotation_csv = '/scratch/brs426/data/annotation.csv'\n",
    "\n",
    "# You shouldn't change the unlabeled_scene_index\n",
    "# The first 106 scenes are unlabeled\n",
    "unlabeled_scene_index = np.arange(106)\n",
    "# The scenes from 106 - 133 are labeled\n",
    "# You should devide the labeled_scene_index into two subsets (training and validation)\n",
    "train_labeled_scene_index = np.arange(106, 132)\n",
    "val_labeled_scene_index = np.arange(132, 134)\n",
    "test_labeled_scene_index = np.arange(132, 134)\n",
    "\n",
    "from helper import compute_ats_bounding_boxes, compute_ts_road_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_up(x):\n",
    "    return int(math.ceil(x / 50.0)) * 50\n",
    "\n",
    "def round_down(x):\n",
    "    return round_up(x) - 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_label = 0\n",
    "class_dict = dict()\n",
    "reverse_class_dict = []\n",
    "for i in range(0, 800, 50):\n",
    "    for j in range(0, 800, 50):\n",
    "        class_dict[(i, j)] = class_label\n",
    "        class_label += 1\n",
    "        reverse_class_dict.append((i, j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0, 0): 0,\n",
       " (0, 50): 1,\n",
       " (0, 100): 2,\n",
       " (0, 150): 3,\n",
       " (0, 200): 4,\n",
       " (0, 250): 5,\n",
       " (0, 300): 6,\n",
       " (0, 350): 7,\n",
       " (0, 400): 8,\n",
       " (0, 450): 9,\n",
       " (0, 500): 10,\n",
       " (0, 550): 11,\n",
       " (0, 600): 12,\n",
       " (0, 650): 13,\n",
       " (0, 700): 14,\n",
       " (0, 750): 15,\n",
       " (50, 0): 16,\n",
       " (50, 50): 17,\n",
       " (50, 100): 18,\n",
       " (50, 150): 19,\n",
       " (50, 200): 20,\n",
       " (50, 250): 21,\n",
       " (50, 300): 22,\n",
       " (50, 350): 23,\n",
       " (50, 400): 24,\n",
       " (50, 450): 25,\n",
       " (50, 500): 26,\n",
       " (50, 550): 27,\n",
       " (50, 600): 28,\n",
       " (50, 650): 29,\n",
       " (50, 700): 30,\n",
       " (50, 750): 31,\n",
       " (100, 0): 32,\n",
       " (100, 50): 33,\n",
       " (100, 100): 34,\n",
       " (100, 150): 35,\n",
       " (100, 200): 36,\n",
       " (100, 250): 37,\n",
       " (100, 300): 38,\n",
       " (100, 350): 39,\n",
       " (100, 400): 40,\n",
       " (100, 450): 41,\n",
       " (100, 500): 42,\n",
       " (100, 550): 43,\n",
       " (100, 600): 44,\n",
       " (100, 650): 45,\n",
       " (100, 700): 46,\n",
       " (100, 750): 47,\n",
       " (150, 0): 48,\n",
       " (150, 50): 49,\n",
       " (150, 100): 50,\n",
       " (150, 150): 51,\n",
       " (150, 200): 52,\n",
       " (150, 250): 53,\n",
       " (150, 300): 54,\n",
       " (150, 350): 55,\n",
       " (150, 400): 56,\n",
       " (150, 450): 57,\n",
       " (150, 500): 58,\n",
       " (150, 550): 59,\n",
       " (150, 600): 60,\n",
       " (150, 650): 61,\n",
       " (150, 700): 62,\n",
       " (150, 750): 63,\n",
       " (200, 0): 64,\n",
       " (200, 50): 65,\n",
       " (200, 100): 66,\n",
       " (200, 150): 67,\n",
       " (200, 200): 68,\n",
       " (200, 250): 69,\n",
       " (200, 300): 70,\n",
       " (200, 350): 71,\n",
       " (200, 400): 72,\n",
       " (200, 450): 73,\n",
       " (200, 500): 74,\n",
       " (200, 550): 75,\n",
       " (200, 600): 76,\n",
       " (200, 650): 77,\n",
       " (200, 700): 78,\n",
       " (200, 750): 79,\n",
       " (250, 0): 80,\n",
       " (250, 50): 81,\n",
       " (250, 100): 82,\n",
       " (250, 150): 83,\n",
       " (250, 200): 84,\n",
       " (250, 250): 85,\n",
       " (250, 300): 86,\n",
       " (250, 350): 87,\n",
       " (250, 400): 88,\n",
       " (250, 450): 89,\n",
       " (250, 500): 90,\n",
       " (250, 550): 91,\n",
       " (250, 600): 92,\n",
       " (250, 650): 93,\n",
       " (250, 700): 94,\n",
       " (250, 750): 95,\n",
       " (300, 0): 96,\n",
       " (300, 50): 97,\n",
       " (300, 100): 98,\n",
       " (300, 150): 99,\n",
       " (300, 200): 100,\n",
       " (300, 250): 101,\n",
       " (300, 300): 102,\n",
       " (300, 350): 103,\n",
       " (300, 400): 104,\n",
       " (300, 450): 105,\n",
       " (300, 500): 106,\n",
       " (300, 550): 107,\n",
       " (300, 600): 108,\n",
       " (300, 650): 109,\n",
       " (300, 700): 110,\n",
       " (300, 750): 111,\n",
       " (350, 0): 112,\n",
       " (350, 50): 113,\n",
       " (350, 100): 114,\n",
       " (350, 150): 115,\n",
       " (350, 200): 116,\n",
       " (350, 250): 117,\n",
       " (350, 300): 118,\n",
       " (350, 350): 119,\n",
       " (350, 400): 120,\n",
       " (350, 450): 121,\n",
       " (350, 500): 122,\n",
       " (350, 550): 123,\n",
       " (350, 600): 124,\n",
       " (350, 650): 125,\n",
       " (350, 700): 126,\n",
       " (350, 750): 127,\n",
       " (400, 0): 128,\n",
       " (400, 50): 129,\n",
       " (400, 100): 130,\n",
       " (400, 150): 131,\n",
       " (400, 200): 132,\n",
       " (400, 250): 133,\n",
       " (400, 300): 134,\n",
       " (400, 350): 135,\n",
       " (400, 400): 136,\n",
       " (400, 450): 137,\n",
       " (400, 500): 138,\n",
       " (400, 550): 139,\n",
       " (400, 600): 140,\n",
       " (400, 650): 141,\n",
       " (400, 700): 142,\n",
       " (400, 750): 143,\n",
       " (450, 0): 144,\n",
       " (450, 50): 145,\n",
       " (450, 100): 146,\n",
       " (450, 150): 147,\n",
       " (450, 200): 148,\n",
       " (450, 250): 149,\n",
       " (450, 300): 150,\n",
       " (450, 350): 151,\n",
       " (450, 400): 152,\n",
       " (450, 450): 153,\n",
       " (450, 500): 154,\n",
       " (450, 550): 155,\n",
       " (450, 600): 156,\n",
       " (450, 650): 157,\n",
       " (450, 700): 158,\n",
       " (450, 750): 159,\n",
       " (500, 0): 160,\n",
       " (500, 50): 161,\n",
       " (500, 100): 162,\n",
       " (500, 150): 163,\n",
       " (500, 200): 164,\n",
       " (500, 250): 165,\n",
       " (500, 300): 166,\n",
       " (500, 350): 167,\n",
       " (500, 400): 168,\n",
       " (500, 450): 169,\n",
       " (500, 500): 170,\n",
       " (500, 550): 171,\n",
       " (500, 600): 172,\n",
       " (500, 650): 173,\n",
       " (500, 700): 174,\n",
       " (500, 750): 175,\n",
       " (550, 0): 176,\n",
       " (550, 50): 177,\n",
       " (550, 100): 178,\n",
       " (550, 150): 179,\n",
       " (550, 200): 180,\n",
       " (550, 250): 181,\n",
       " (550, 300): 182,\n",
       " (550, 350): 183,\n",
       " (550, 400): 184,\n",
       " (550, 450): 185,\n",
       " (550, 500): 186,\n",
       " (550, 550): 187,\n",
       " (550, 600): 188,\n",
       " (550, 650): 189,\n",
       " (550, 700): 190,\n",
       " (550, 750): 191,\n",
       " (600, 0): 192,\n",
       " (600, 50): 193,\n",
       " (600, 100): 194,\n",
       " (600, 150): 195,\n",
       " (600, 200): 196,\n",
       " (600, 250): 197,\n",
       " (600, 300): 198,\n",
       " (600, 350): 199,\n",
       " (600, 400): 200,\n",
       " (600, 450): 201,\n",
       " (600, 500): 202,\n",
       " (600, 550): 203,\n",
       " (600, 600): 204,\n",
       " (600, 650): 205,\n",
       " (600, 700): 206,\n",
       " (600, 750): 207,\n",
       " (650, 0): 208,\n",
       " (650, 50): 209,\n",
       " (650, 100): 210,\n",
       " (650, 150): 211,\n",
       " (650, 200): 212,\n",
       " (650, 250): 213,\n",
       " (650, 300): 214,\n",
       " (650, 350): 215,\n",
       " (650, 400): 216,\n",
       " (650, 450): 217,\n",
       " (650, 500): 218,\n",
       " (650, 550): 219,\n",
       " (650, 600): 220,\n",
       " (650, 650): 221,\n",
       " (650, 700): 222,\n",
       " (650, 750): 223,\n",
       " (700, 0): 224,\n",
       " (700, 50): 225,\n",
       " (700, 100): 226,\n",
       " (700, 150): 227,\n",
       " (700, 200): 228,\n",
       " (700, 250): 229,\n",
       " (700, 300): 230,\n",
       " (700, 350): 231,\n",
       " (700, 400): 232,\n",
       " (700, 450): 233,\n",
       " (700, 500): 234,\n",
       " (700, 550): 235,\n",
       " (700, 600): 236,\n",
       " (700, 650): 237,\n",
       " (700, 700): 238,\n",
       " (700, 750): 239,\n",
       " (750, 0): 240,\n",
       " (750, 50): 241,\n",
       " (750, 100): 242,\n",
       " (750, 150): 243,\n",
       " (750, 200): 244,\n",
       " (750, 250): 245,\n",
       " (750, 300): 246,\n",
       " (750, 350): 247,\n",
       " (750, 400): 248,\n",
       " (750, 450): 249,\n",
       " (750, 500): 250,\n",
       " (750, 550): 251,\n",
       " (750, 600): 252,\n",
       " (750, 650): 253,\n",
       " (750, 700): 254,\n",
       " (750, 750): 255}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 350)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reverse_class_dict[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    BLOCK_SIZE = 5\n",
    "    images = []\n",
    "    target = []\n",
    "    road_maps = []\n",
    "    road_bins = []\n",
    "    bbs = []\n",
    "    target_counts = []\n",
    "    target_x_off = []\n",
    "    target_y_off = []\n",
    "    for x in batch:\n",
    "        \n",
    "        grid = []\n",
    "        # Get road_image and cast it to float\n",
    "        road_image = torch.as_tensor(x[2])\n",
    "        road_maps.append(road_image)\n",
    "        road_image = road_image.float()\n",
    "        \n",
    "        # Split up into blocks and assign pixel value for block\n",
    "        for x_ in range(0, 800, BLOCK_SIZE):\n",
    "            for y in range(0, 800, BLOCK_SIZE):\n",
    "                block = road_image[x_:x_+BLOCK_SIZE, y:y+BLOCK_SIZE]\n",
    "                score = torch.sum(block).item()\n",
    "                # If more than have the pixels are 1, classify as road\n",
    "                if score > (BLOCK_SIZE**2) / 2:\n",
    "                    grid.append(1.0)\n",
    "                else:\n",
    "                    grid.append(0.0)\n",
    "                \n",
    "        road_bins.append(torch.Tensor(grid))\n",
    "        \n",
    "        # Collect six images for this sample. \n",
    "        six_images = []\n",
    "        for i in range(6):\n",
    "            six_images.append(torch.Tensor(x[0][i]))\n",
    "        \n",
    "        \n",
    "        # target\n",
    "        bb_tens = x[1]['bounding_box']\n",
    "        current_bbs = []\n",
    "        bins_x_off = np.zeros(256)\n",
    "        bins_y_off = np.zeros(256)\n",
    "        bins = np.zeros(256)\n",
    "        counts = np.zeros(90)\n",
    "        count = 0\n",
    "        \n",
    "        for i, corners in enumerate(bb_tens):\n",
    "#             if x[1]['category'][i] not in [1, 3, 6, 8]:\n",
    "            # Get its four bird's-eye view coordinates. \n",
    "            point_squence = torch.stack([corners[:, 0], corners[:, 1], corners[:, 3], corners[:, 2]])\n",
    "            xs = point_squence.T[0] * 10 + 400\n",
    "            ys = -point_squence.T[1] * 10 + 400\n",
    "\n",
    "            # Grab the current bounding box. \n",
    "            current_bbs.append((xs, ys))\n",
    "\n",
    "            # Find the bin/grid cell it falls in, get its class mapping. \n",
    "            center_x, center_y = torch.mean(xs).item(), torch.mean(ys).item()\n",
    "            key = (round_down(center_x), round_down(center_y))\n",
    "            \n",
    "            bin_center_x, bin_center_y = key[0] + 25, key[1] + 25\n",
    "            \n",
    "            x_offset = center_x - bin_center_x\n",
    "            y_offset = center_y - bin_center_y\n",
    "            \n",
    "            x_offset /= 25\n",
    "            y_offset /= 25\n",
    "            \n",
    "            if key not in class_dict:\n",
    "                print(key)\n",
    "            bin_id = class_dict[key]\n",
    "            bins[bin_id] = 1\n",
    "            count += 1\n",
    "            \n",
    "            bins_x_off[bin_id] = x_offset\n",
    "            bins_y_off[bin_id] = y_offset\n",
    "            \n",
    "            \n",
    "        \n",
    "        counts[count] = 1\n",
    "\n",
    "        # Label Smoothing #\n",
    "        if count > 10 and count < 88:\n",
    "            counts[count+1] = 0.2\n",
    "            counts[count-1] = 0.2\n",
    "        target_counts.append(torch.Tensor(counts))\n",
    "        \n",
    "        images.append(torch.stack(six_images))\n",
    "                \n",
    "        target.append(torch.Tensor(bins))\n",
    "        target_x_off.append(torch.Tensor(bins_x_off))\n",
    "        target_y_off.append(torch.Tensor(bins_y_off))\n",
    "        \n",
    "        bbs.append(current_bbs)\n",
    "                \n",
    "    boom = torch.stack(images), torch.stack(target), torch.stack(road_maps), bbs, torch.stack(target_counts), torch.stack(road_bins), torch.stack(target_x_off), torch.stack(target_y_off)\n",
    "    return boom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The labeled dataset can only be retrieved by sample.\n",
    "# And all the returned data are tuple of tensors, since bounding boxes may have different size\n",
    "# You can choose whether the loader returns the extra_info. It is optional. You don't have to use it.\n",
    "val_transform = transforms.ToTensor()\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomApply([\n",
    "        transforms.ColorJitter(brightness = 0.5, contrast = 0.5, saturation = 0.4, hue = (-0.5, 0.5)),\n",
    "        transforms.Grayscale(3),\n",
    "#         transforms.RandomAffine(3),\n",
    "    ]),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "\n",
    "labeled_trainset = LabeledDataset(image_folder=image_folder,\n",
    "                                  annotation_file=annotation_csv,\n",
    "                                  scene_index=train_labeled_scene_index,\n",
    "                                  transform=train_transform,\n",
    "                                  extra_info=True\n",
    "                                 )\n",
    "labeled_valset = LabeledDataset(image_folder=image_folder,\n",
    "                                  annotation_file=annotation_csv,\n",
    "                                  scene_index=val_labeled_scene_index,\n",
    "                                  transform=val_transform,\n",
    "                                  extra_info=True\n",
    "                                 )\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(labeled_trainset, batch_size=16, num_workers=5, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = torch.utils.data.DataLoader(labeled_valset, batch_size=16, num_workers=5, shuffle=True, collate_fn=collate_fn)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        \n",
    "        self.encoder = torchvision.models.resnet50()\n",
    "        self.encoder.fc = nn.Identity()\n",
    "        self.concat_dim = 180 * 6\n",
    "        \n",
    "        self.compress = nn.Sequential(OrderedDict([\n",
    "            ('linear0', nn.Linear(2048, 180)),\n",
    "            ('drop', nn.Dropout(p = 0.5)),\n",
    "            ('relu', nn.ReLU()),\n",
    "        ]))\n",
    "        \n",
    "        self.classification = nn.Sequential(OrderedDict([\n",
    "            ('linear1', nn.Linear(self.concat_dim, 256)),\n",
    "        ]))\n",
    "        \n",
    "        self.x_offset = nn.Sequential(OrderedDict([\n",
    "            ('xoff1', nn.Linear(self.concat_dim, 256)),\n",
    "            ('tanh1', nn.Tanh())\n",
    "        ]))\n",
    "        \n",
    "        self.y_offset = nn.Sequential(OrderedDict([\n",
    "            ('yoff1', nn.Linear(self.concat_dim, 256)),\n",
    "            ('tanh2', nn.Tanh())\n",
    "        ]))\n",
    "        \n",
    "        self.counts = nn.Sequential(OrderedDict([\n",
    "            ('count1', nn.Linear(self.concat_dim, 90))\n",
    "        ]))\n",
    "        \n",
    "        self.segmentation = nn.Sequential(OrderedDict([\n",
    "            ('linear1_segmentation', nn.Linear(self.concat_dim, 25600)),\n",
    "            ('sigmoid', nn.Sigmoid())\n",
    "        ]))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        num_images = x.shape[1]\n",
    "        channels = x.shape[2]\n",
    "        height = x.shape[3]\n",
    "        width = x.shape[4]\n",
    "        # Reshape here\n",
    "        x = x.view(-1, channels, height, width)\n",
    "        x = self.encoder(x)\n",
    "        x = self.compress(x)\n",
    "        x = x.view(-1, self.concat_dim)\n",
    "        return self.classification(x), self.counts(x), self.segmentation(x), self.x_offset(x), self.y_offset(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SimpleModel()\n",
    "\n",
    "# Weighting certain classes more. \n",
    "# positive_weight = torch.ones(256).to(device)\n",
    "# for (x, y), bin_id in class_dict.items():\n",
    "#     if abs(x - 400) <= 200 and abs(y - 400) <= 200:\n",
    "#         positive_weight[bin_id] = 2\n",
    "\n",
    "# for name, param in model.encoder.named_parameters():\n",
    "#     if(\"bn\" not in name):\n",
    "#         param.requires_grad = False\n",
    "        \n",
    "# unfreeze_layers = [model.encoder.layer3, model.encoder.layer4]\n",
    "# for layer in unfreeze_layers:\n",
    "#     for param in layer.parameters():\n",
    "#         param.requires_grad = True\n",
    "        \n",
    "model = model.to(device)\n",
    "bin_criterion = nn.BCEWithLogitsLoss()\n",
    "count_criterion = nn.BCEWithLogitsLoss()\n",
    "segmentation_criterion = nn.BCELoss()\n",
    "x_offset_criterion = nn.MSELoss()\n",
    "y_offset_criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=2e-4)\n",
    "best_val_loss = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    labeled_trainset = LabeledDataset(image_folder=image_folder,\n",
    "                                  annotation_file=annotation_csv,\n",
    "                                  scene_index=train_labeled_scene_index,\n",
    "                                  transform=train_transform,\n",
    "                                  extra_info=True\n",
    "                                 )\n",
    "    train_loader = torch.utils.data.DataLoader(labeled_trainset, batch_size=10, num_workers=10, shuffle=True, collate_fn=collate_fn)\n",
    "    \n",
    "    train_losses = []\n",
    "    bin_losses = []\n",
    "    count_losses = []\n",
    "    segmentation_losses = []\n",
    "    x_off_losses = []\n",
    "    y_off_losses = []\n",
    "    for i, (sample, target, road_img, bbs, target_count, road_bins, target_x_off, target_y_off) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        sample = sample.to(device)\n",
    "        target = target.to(device)\n",
    "        target_count = target_count.to(device)\n",
    "        road_bins = road_bins.to(device)\n",
    "        target_x_off = target_x_off.to(device)\n",
    "        target_y_off = target_y_off.to(device)\n",
    "        \n",
    "        y_hat, y_count, segmentation, x_offset, y_offset = model(sample)\n",
    "        \n",
    "        bin_loss = bin_criterion(y_hat, target.float())\n",
    "        count_loss = count_criterion(y_count, target_count.float())\n",
    "        segmentation_loss = segmentation_criterion(segmentation, road_bins.float())\n",
    "        \n",
    "        \n",
    "        x_off_loss = 0\n",
    "        y_off_loss = 0\n",
    "        for idx, vector in enumerate(target):\n",
    "            # Get the ids that are equal to 1. \n",
    "            bin_ids = (target[idx] == 1).nonzero()\n",
    "            x_off_loss += x_offset_criterion(x_offset[idx][bin_ids], target_x_off[idx][bin_ids])\n",
    "            y_off_loss += y_offset_criterion(y_offset[idx][bin_ids], target_y_off[idx][bin_ids])\n",
    "\n",
    "        loss = bin_loss + count_loss + segmentation_loss + 0.05 * x_off_loss + 0.05 * y_off_loss\n",
    "        \n",
    "        train_losses.append(loss.item())\n",
    "        bin_losses.append(bin_loss.item())\n",
    "        count_losses.append(count_loss.item())\n",
    "        segmentation_losses.append(segmentation_loss.item())\n",
    "        x_off_losses.append(0.05 * x_off_loss.item())\n",
    "        y_off_losses.append(0.05 * y_off_loss.item())\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % 50 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, i * len(sample), len(train_loader.dataset),\n",
    "                50. * i / len(train_loader), loss.item()))\n",
    "            \n",
    "    print(\"\\nAverage Train Epoch Loss: \", np.mean(train_losses))\n",
    "    print(\"Average Train Bin Epoch Loss: \", np.mean(bin_losses))\n",
    "    print(\"Average Train Count Epoch Loss: \", np.mean(count_losses))\n",
    "    print(\"Average Train Segmentation Epoch Loss: \", np.mean(segmentation_losses))\n",
    "    print(\"Average Train X-Offset Epoch Loss: \", np.mean(x_off_losses))\n",
    "    print(\"Average Train Y-Offset Epoch Loss: \", np.mean(y_off_losses))\n",
    "            \n",
    "def val():\n",
    "    model.eval()\n",
    "    val_losses = []\n",
    "    bin_losses = []\n",
    "    count_losses = []\n",
    "    segmentation_losses = []\n",
    "    x_off_losses = []\n",
    "    y_off_losses = []\n",
    "    count_correct = 0\n",
    "    count_off_by_1 = 0\n",
    "    total_count = 0\n",
    "    bin_correct = 0\n",
    "    total_bins = 0\n",
    "    for i, (sample, target, road_img, bbs, target_count, road_bins, target_x_off, target_y_off) in enumerate(val_loader):\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        sample = sample.to(device)\n",
    "        target = target.to(device)\n",
    "        road_bins = road_bins.to(device)\n",
    "        target_count = target_count.to(device)\n",
    "        target_x_off = target_x_off.to(device)\n",
    "        target_y_off = target_y_off.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            y_hat, y_count, segmentation, x_offset, y_offset = model(sample)\n",
    "            \n",
    "            bin_loss = bin_criterion(y_hat, target.float())\n",
    "            count_loss = count_criterion(y_count, target_count.float())\n",
    "            segmentation_loss = segmentation_criterion(segmentation, road_bins.float())\n",
    "            \n",
    "            x_off_loss = 0\n",
    "            y_off_loss = 0\n",
    "            for idx, vector in enumerate(target):\n",
    "                # Get the ids that are equal to 1. \n",
    "                bin_ids = (target[idx] == 1).nonzero()\n",
    "                x_off_loss += x_offset_criterion(x_offset[idx][bin_ids], target_x_off[idx][bin_ids])\n",
    "                y_off_loss += y_offset_criterion(y_offset[idx][bin_ids], target_y_off[idx][bin_ids])\n",
    "                \n",
    "            loss = bin_loss + count_loss + segmentation_loss + 0.05 * x_off_loss + 0.05 * y_off_loss\n",
    "\n",
    "            val_losses.append(loss.item())\n",
    "            bin_losses.append(bin_loss.item())\n",
    "            count_losses.append(count_loss.item())\n",
    "            segmentation_losses.append(segmentation_loss.item())\n",
    "            x_off_losses.append(0.05 * x_off_loss.item())\n",
    "            y_off_losses.append(0.05 * y_off_loss.item())\n",
    "            \n",
    "    print(\"Average Validation Epoch Loss: \", np.mean(val_losses))\n",
    "    print(\"Average Validation Bin Epoch Loss: \", np.mean(bin_losses))\n",
    "    print(\"Average Validation Count Epoch Loss: \", np.mean(count_losses))\n",
    "    print(\"Average Validation Segmentation Epoch Loss: \", np.mean(segmentation_losses))\n",
    "    print(\"Average Validation X-Offset Epoch Loss: \", np.mean(x_off_losses))\n",
    "    print(\"Average Validation Y-Offset Epoch Loss: \", np.mean(y_off_losses))\n",
    "#     print(\"\\tAverage Validation Count Accuracy: \", 100*count_correct/total_count)\n",
    "#     print(\"\\tAverage Validation Count-off-by-1 Accuracy: \", 100*count_off_by_1/total_count)\n",
    "#     if total_bins != 0:\n",
    "#         print(\"\\tAverage Validation Bin Accuracy: \", 100*bin_correct/total_bins)\n",
    "#     print(\"\\n\")\n",
    "    global best_val_loss\n",
    "    if np.mean(val_losses) < best_val_loss:\n",
    "        best_val_loss = np.mean(val_losses)\n",
    "        torch.save(model.state_dict(), '/scratch/vr1059/all_six_images_classify_count_offset.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/3276 (0%)]\tLoss: 2.525649\n",
      "Train Epoch: 0 [500/3276 (8%)]\tLoss: 1.369438\n",
      "Train Epoch: 0 [1000/3276 (15%)]\tLoss: 1.156603\n",
      "Train Epoch: 0 [1500/3276 (23%)]\tLoss: 1.085791\n",
      "Train Epoch: 0 [2000/3276 (30%)]\tLoss: 1.081921\n",
      "Train Epoch: 0 [2500/3276 (38%)]\tLoss: 1.035587\n",
      "Train Epoch: 0 [3000/3276 (46%)]\tLoss: 1.009162\n",
      "\n",
      "Average Train Epoch Loss:  1.1585347372584227\n",
      "Average Train Bin Epoch Loss:  0.23283358122699144\n",
      "Average Train Count Epoch Loss:  0.10069402543509878\n",
      "Average Train Segmentation Epoch Loss:  0.4272751302072188\n",
      "Average Train X-Offset Epoch Loss:  0.21910355628990547\n",
      "Average Train Y-Offset Epoch Loss:  0.17862843585813917\n",
      "Average Validation Epoch Loss:  1.179866187274456\n",
      "Average Validation Bin Epoch Loss:  0.23227671813219786\n",
      "Average Validation Count Epoch Loss:  0.0677193864248693\n",
      "Average Validation Segmentation Epoch Loss:  0.3983976896852255\n",
      "Average Validation X-Offset Epoch Loss:  0.2697022318840027\n",
      "Average Validation Y-Offset Epoch Loss:  0.211770149320364\n",
      "Train Epoch: 1 [0/3276 (0%)]\tLoss: 1.005390\n",
      "Train Epoch: 1 [500/3276 (8%)]\tLoss: 1.260070\n",
      "Train Epoch: 1 [1000/3276 (15%)]\tLoss: 1.032708\n",
      "Train Epoch: 1 [1500/3276 (23%)]\tLoss: 1.052878\n",
      "Train Epoch: 1 [2000/3276 (30%)]\tLoss: 1.118322\n",
      "Train Epoch: 1 [2500/3276 (38%)]\tLoss: 1.017154\n",
      "Train Epoch: 1 [3000/3276 (46%)]\tLoss: 0.996538\n",
      "\n",
      "Average Train Epoch Loss:  1.0100797465661677\n",
      "Average Train Bin Epoch Loss:  0.2089185587516645\n",
      "Average Train Count Epoch Loss:  0.06865760935016157\n",
      "Average Train Segmentation Epoch Loss:  0.40512100289144165\n",
      "Average Train X-Offset Epoch Loss:  0.18325784678866225\n",
      "Average Train Y-Offset Epoch Loss:  0.144124722244536\n",
      "Average Validation Epoch Loss:  1.1625930443406105\n",
      "Average Validation Bin Epoch Loss:  0.2280951952561736\n",
      "Average Validation Count Epoch Loss:  0.06800847384147346\n",
      "Average Validation Segmentation Epoch Loss:  0.3960789702832699\n",
      "Average Validation X-Offset Epoch Loss:  0.26524116396903996\n",
      "Average Validation Y-Offset Epoch Loss:  0.20516922250390052\n",
      "Train Epoch: 2 [0/3276 (0%)]\tLoss: 0.942412\n",
      "Train Epoch: 2 [500/3276 (8%)]\tLoss: 1.044352\n",
      "Train Epoch: 2 [1000/3276 (15%)]\tLoss: 1.011891\n",
      "Train Epoch: 2 [1500/3276 (23%)]\tLoss: 0.980596\n",
      "Train Epoch: 2 [2000/3276 (30%)]\tLoss: 0.977054\n",
      "Train Epoch: 2 [2500/3276 (38%)]\tLoss: 0.966591\n",
      "Train Epoch: 2 [3000/3276 (46%)]\tLoss: 0.982337\n",
      "\n",
      "Average Train Epoch Loss:  0.9758199169868376\n",
      "Average Train Bin Epoch Loss:  0.20529133694746146\n",
      "Average Train Count Epoch Loss:  0.06628414623939045\n",
      "Average Train Segmentation Epoch Loss:  0.39313964055078787\n",
      "Average Train X-Offset Epoch Loss:  0.1765713351892262\n",
      "Average Train Y-Offset Epoch Loss:  0.13453344906248696\n",
      "Average Validation Epoch Loss:  1.1578571312129498\n",
      "Average Validation Bin Epoch Loss:  0.22583347372710705\n",
      "Average Validation Count Epoch Loss:  0.06737411511130631\n",
      "Average Validation Segmentation Epoch Loss:  0.387206194922328\n",
      "Average Validation X-Offset Epoch Loss:  0.2651041574776173\n",
      "Average Validation Y-Offset Epoch Loss:  0.21233917027711868\n",
      "Train Epoch: 3 [0/3276 (0%)]\tLoss: 0.824343\n",
      "Train Epoch: 3 [500/3276 (8%)]\tLoss: 1.001776\n",
      "Train Epoch: 3 [1000/3276 (15%)]\tLoss: 0.956873\n",
      "Train Epoch: 3 [1500/3276 (23%)]\tLoss: 0.916070\n",
      "Train Epoch: 3 [2000/3276 (30%)]\tLoss: 0.891312\n",
      "Train Epoch: 3 [2500/3276 (38%)]\tLoss: 0.812781\n",
      "Train Epoch: 3 [3000/3276 (46%)]\tLoss: 0.929611\n",
      "\n",
      "Average Train Epoch Loss:  0.9376049452438587\n",
      "Average Train Bin Epoch Loss:  0.20130100823575403\n",
      "Average Train Count Epoch Loss:  0.06402660197601086\n",
      "Average Train Segmentation Epoch Loss:  0.37183397581301086\n",
      "Average Train X-Offset Epoch Loss:  0.17353012005730375\n",
      "Average Train Y-Offset Epoch Loss:  0.12691322682289088\n",
      "Average Validation Epoch Loss:  1.157602198421955\n",
      "Average Validation Bin Epoch Loss:  0.22651408333331347\n",
      "Average Validation Count Epoch Loss:  0.06451367842964828\n",
      "Average Validation Segmentation Epoch Loss:  0.37798601016402245\n",
      "Average Validation X-Offset Epoch Loss:  0.2651692904531956\n",
      "Average Validation Y-Offset Epoch Loss:  0.2234191119670868\n",
      "Train Epoch: 4 [0/3276 (0%)]\tLoss: 0.847077\n",
      "Train Epoch: 4 [500/3276 (8%)]\tLoss: 0.773248\n",
      "Train Epoch: 4 [1000/3276 (15%)]\tLoss: 1.214141\n",
      "Train Epoch: 4 [1500/3276 (23%)]\tLoss: 1.032321\n",
      "Train Epoch: 4 [2000/3276 (30%)]\tLoss: 0.834570\n",
      "Train Epoch: 4 [2500/3276 (38%)]\tLoss: 0.844311\n",
      "Train Epoch: 4 [3000/3276 (46%)]\tLoss: 0.804209\n",
      "\n",
      "Average Train Epoch Loss:  0.8883869462623829\n",
      "Average Train Bin Epoch Loss:  0.1948551845895808\n",
      "Average Train Count Epoch Loss:  0.061221571207591675\n",
      "Average Train Segmentation Epoch Loss:  0.33782528867808786\n",
      "Average Train X-Offset Epoch Loss:  0.1737708890583457\n",
      "Average Train Y-Offset Epoch Loss:  0.12071400479209134\n",
      "Average Validation Epoch Loss:  1.1133733950555325\n",
      "Average Validation Bin Epoch Loss:  0.222242402844131\n",
      "Average Validation Count Epoch Loss:  0.06400832091458142\n",
      "Average Validation Segmentation Epoch Loss:  0.355294082313776\n",
      "Average Validation X-Offset Epoch Loss:  0.26473150551319125\n",
      "Average Validation Y-Offset Epoch Loss:  0.2070970892906189\n",
      "Train Epoch: 5 [0/3276 (0%)]\tLoss: 0.770347\n",
      "Train Epoch: 5 [500/3276 (8%)]\tLoss: 0.721686\n",
      "Train Epoch: 5 [1000/3276 (15%)]\tLoss: 0.918145\n",
      "Train Epoch: 5 [1500/3276 (23%)]\tLoss: 0.819907\n",
      "Train Epoch: 5 [2000/3276 (30%)]\tLoss: 0.854894\n",
      "Train Epoch: 5 [2500/3276 (38%)]\tLoss: 0.890760\n",
      "Train Epoch: 5 [3000/3276 (46%)]\tLoss: 0.867523\n",
      "\n",
      "Average Train Epoch Loss:  0.8432548233285183\n",
      "Average Train Bin Epoch Loss:  0.18796122287649933\n",
      "Average Train Count Epoch Loss:  0.058549351626779975\n",
      "Average Train Segmentation Epoch Loss:  0.30993716777643054\n",
      "Average Train X-Offset Epoch Loss:  0.17250167398554525\n",
      "Average Train Y-Offset Epoch Loss:  0.1143054000669863\n",
      "Average Validation Epoch Loss:  1.080194216221571\n",
      "Average Validation Bin Epoch Loss:  0.21880451869219542\n",
      "Average Validation Count Epoch Loss:  0.0630160307046026\n",
      "Average Validation Segmentation Epoch Loss:  0.33381788060069084\n",
      "Average Validation X-Offset Epoch Loss:  0.25991700142622\n",
      "Average Validation Y-Offset Epoch Loss:  0.2046387627720833\n",
      "Train Epoch: 6 [0/3276 (0%)]\tLoss: 0.765785\n",
      "Train Epoch: 6 [500/3276 (8%)]\tLoss: 0.821563\n",
      "Train Epoch: 6 [1000/3276 (15%)]\tLoss: 0.954815\n",
      "Train Epoch: 6 [1500/3276 (23%)]\tLoss: 0.701100\n",
      "Train Epoch: 6 [2000/3276 (30%)]\tLoss: 0.845782\n",
      "Train Epoch: 6 [2500/3276 (38%)]\tLoss: 0.942784\n",
      "Train Epoch: 6 [3000/3276 (46%)]\tLoss: 0.796788\n",
      "\n",
      "Average Train Epoch Loss:  0.8008141595779396\n",
      "Average Train Bin Epoch Loss:  0.18266203240832177\n",
      "Average Train Count Epoch Loss:  0.0567226450685866\n",
      "Average Train Segmentation Epoch Loss:  0.28807815205214954\n",
      "Average Train X-Offset Epoch Loss:  0.16670474313744685\n",
      "Average Train Y-Offset Epoch Loss:  0.10664658365634884\n",
      "Average Validation Epoch Loss:  1.0827405601739883\n",
      "Average Validation Bin Epoch Loss:  0.2211657501757145\n",
      "Average Validation Count Epoch Loss:  0.06351978471502662\n",
      "Average Validation Segmentation Epoch Loss:  0.3227489357814193\n",
      "Average Validation X-Offset Epoch Loss:  0.2629827991127968\n",
      "Average Validation Y-Offset Epoch Loss:  0.212323272228241\n",
      "Train Epoch: 7 [0/3276 (0%)]\tLoss: 0.669397\n",
      "Train Epoch: 7 [500/3276 (8%)]\tLoss: 0.734100\n",
      "Train Epoch: 7 [1000/3276 (15%)]\tLoss: 0.905921\n",
      "Train Epoch: 7 [1500/3276 (23%)]\tLoss: 0.844612\n",
      "Train Epoch: 7 [2000/3276 (30%)]\tLoss: 0.747614\n",
      "Train Epoch: 7 [2500/3276 (38%)]\tLoss: 0.673206\n",
      "Train Epoch: 7 [3000/3276 (46%)]\tLoss: 0.706890\n",
      "\n",
      "Average Train Epoch Loss:  0.7753010259532347\n",
      "Average Train Bin Epoch Loss:  0.17888040095567703\n",
      "Average Train Count Epoch Loss:  0.055628677773312096\n",
      "Average Train Segmentation Epoch Loss:  0.27671166523018986\n",
      "Average Train X-Offset Epoch Loss:  0.16428963113121872\n",
      "Average Train Y-Offset Epoch Loss:  0.09979064817108758\n",
      "Average Validation Epoch Loss:  1.1223727464675903\n",
      "Average Validation Bin Epoch Loss:  0.22166858986020088\n",
      "Average Validation Count Epoch Loss:  0.06323527288623154\n",
      "Average Validation Segmentation Epoch Loss:  0.334554823115468\n",
      "Average Validation X-Offset Epoch Loss:  0.2718063294887543\n",
      "Average Validation Y-Offset Epoch Loss:  0.23110771551728249\n",
      "Train Epoch: 8 [0/3276 (0%)]\tLoss: 0.678326\n",
      "Train Epoch: 8 [500/3276 (8%)]\tLoss: 0.791087\n",
      "Train Epoch: 8 [1000/3276 (15%)]\tLoss: 0.707624\n",
      "Train Epoch: 8 [1500/3276 (23%)]\tLoss: 0.861837\n",
      "Train Epoch: 8 [2000/3276 (30%)]\tLoss: 0.847995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 8 [2500/3276 (38%)]\tLoss: 0.752709\n",
      "Train Epoch: 8 [3000/3276 (46%)]\tLoss: 0.800835\n",
      "\n",
      "Average Train Epoch Loss:  0.7557330718491135\n",
      "Average Train Bin Epoch Loss:  0.17603951588091327\n",
      "Average Train Count Epoch Loss:  0.054650306247356464\n",
      "Average Train Segmentation Epoch Loss:  0.26680222903264733\n",
      "Average Train X-Offset Epoch Loss:  0.16240386848406096\n",
      "Average Train Y-Offset Epoch Loss:  0.09583714477172713\n",
      "Average Validation Epoch Loss:  1.0472346358001232\n",
      "Average Validation Bin Epoch Loss:  0.21512788720428944\n",
      "Average Validation Count Epoch Loss:  0.06287957448512316\n",
      "Average Validation Segmentation Epoch Loss:  0.29695599153637886\n",
      "Average Validation X-Offset Epoch Loss:  0.260307177901268\n",
      "Average Validation Y-Offset Epoch Loss:  0.21196398884058001\n",
      "Train Epoch: 9 [0/3276 (0%)]\tLoss: 0.680860\n",
      "Train Epoch: 9 [500/3276 (8%)]\tLoss: 0.682982\n",
      "Train Epoch: 9 [1000/3276 (15%)]\tLoss: 0.816746\n",
      "Train Epoch: 9 [1500/3276 (23%)]\tLoss: 0.867852\n",
      "Train Epoch: 9 [2000/3276 (30%)]\tLoss: 0.825553\n",
      "Train Epoch: 9 [2500/3276 (38%)]\tLoss: 0.838295\n",
      "Train Epoch: 9 [3000/3276 (46%)]\tLoss: 0.755099\n",
      "\n",
      "Average Train Epoch Loss:  0.7344068182496036\n",
      "Average Train Bin Epoch Loss:  0.1735403763993484\n",
      "Average Train Count Epoch Loss:  0.05380542719418683\n",
      "Average Train Segmentation Epoch Loss:  0.2571081147960773\n",
      "Average Train X-Offset Epoch Loss:  0.1589855233707079\n",
      "Average Train Y-Offset Epoch Loss:  0.09096737055153382\n",
      "Average Validation Epoch Loss:  1.0679485239088535\n",
      "Average Validation Bin Epoch Loss:  0.21872652787715197\n",
      "Average Validation Count Epoch Loss:  0.06374322180636227\n",
      "Average Validation Segmentation Epoch Loss:  0.31030060444027185\n",
      "Average Validation X-Offset Epoch Loss:  0.2634189501404762\n",
      "Average Validation Y-Offset Epoch Loss:  0.21175919249653818\n",
      "Train Epoch: 10 [0/3276 (0%)]\tLoss: 0.653780\n",
      "Train Epoch: 10 [500/3276 (8%)]\tLoss: 0.667586\n",
      "Train Epoch: 10 [1000/3276 (15%)]\tLoss: 0.692969\n",
      "Train Epoch: 10 [1500/3276 (23%)]\tLoss: 0.669656\n",
      "Train Epoch: 10 [2000/3276 (30%)]\tLoss: 0.709416\n",
      "Train Epoch: 10 [2500/3276 (38%)]\tLoss: 0.757798\n",
      "Train Epoch: 10 [3000/3276 (46%)]\tLoss: 0.651877\n",
      "\n",
      "Average Train Epoch Loss:  0.7168992654215999\n",
      "Average Train Bin Epoch Loss:  0.17103284622383555\n",
      "Average Train Count Epoch Loss:  0.052962202340273594\n",
      "Average Train Segmentation Epoch Loss:  0.2488385371000665\n",
      "Average Train X-Offset Epoch Loss:  0.15719871175725286\n",
      "Average Train Y-Offset Epoch Loss:  0.08686696439072854\n",
      "Average Validation Epoch Loss:  1.0460331104695797\n",
      "Average Validation Bin Epoch Loss:  0.21308261435478926\n",
      "Average Validation Count Epoch Loss:  0.0626265350729227\n",
      "Average Validation Segmentation Epoch Loss:  0.30934896133840084\n",
      "Average Validation X-Offset Epoch Loss:  0.26317115128040314\n",
      "Average Validation Y-Offset Epoch Loss:  0.19780383780598643\n",
      "Train Epoch: 11 [0/3276 (0%)]\tLoss: 0.766786\n",
      "Train Epoch: 11 [500/3276 (8%)]\tLoss: 0.881722\n",
      "Train Epoch: 11 [1000/3276 (15%)]\tLoss: 0.720568\n",
      "Train Epoch: 11 [1500/3276 (23%)]\tLoss: 0.635002\n",
      "Train Epoch: 11 [2000/3276 (30%)]\tLoss: 0.666004\n",
      "Train Epoch: 11 [2500/3276 (38%)]\tLoss: 0.652150\n",
      "Train Epoch: 11 [3000/3276 (46%)]\tLoss: 0.720783\n",
      "\n",
      "Average Train Epoch Loss:  0.6994755041853684\n",
      "Average Train Bin Epoch Loss:  0.16900707233878898\n",
      "Average Train Count Epoch Loss:  0.05205722399646553\n",
      "Average Train Segmentation Epoch Loss:  0.2413527407433565\n",
      "Average Train X-Offset Epoch Loss:  0.15444948983992018\n",
      "Average Train Y-Offset Epoch Loss:  0.08260897268064138\n",
      "Average Validation Epoch Loss:  1.0263721458613873\n",
      "Average Validation Bin Epoch Loss:  0.2101863706484437\n",
      "Average Validation Count Epoch Loss:  0.062024102779105306\n",
      "Average Validation Segmentation Epoch Loss:  0.28751768451184034\n",
      "Average Validation X-Offset Epoch Loss:  0.2643278419971466\n",
      "Average Validation Y-Offset Epoch Loss:  0.202316140383482\n",
      "Train Epoch: 12 [0/3276 (0%)]\tLoss: 0.798362\n",
      "Train Epoch: 12 [500/3276 (8%)]\tLoss: 0.583452\n",
      "Train Epoch: 12 [1000/3276 (15%)]\tLoss: 0.659088\n",
      "Train Epoch: 12 [1500/3276 (23%)]\tLoss: 0.612442\n",
      "Train Epoch: 12 [2000/3276 (30%)]\tLoss: 0.674403\n",
      "Train Epoch: 12 [2500/3276 (38%)]\tLoss: 0.724104\n",
      "Train Epoch: 12 [3000/3276 (46%)]\tLoss: 0.756261\n",
      "\n",
      "Average Train Epoch Loss:  0.6841477246546164\n",
      "Average Train Bin Epoch Loss:  0.16733877892356094\n",
      "Average Train Count Epoch Loss:  0.05134112275455419\n",
      "Average Train Segmentation Epoch Loss:  0.23486976309611304\n",
      "Average Train X-Offset Epoch Loss:  0.15198456356074752\n",
      "Average Train Y-Offset Epoch Loss:  0.07861349252847637\n",
      "Train Epoch: 13 [500/3276 (8%)]\tLoss: 0.725071\n",
      "Train Epoch: 13 [1000/3276 (15%)]\tLoss: 0.631777\n",
      "Train Epoch: 13 [1500/3276 (23%)]\tLoss: 0.707154\n",
      "Train Epoch: 13 [2000/3276 (30%)]\tLoss: 0.684371\n",
      "Train Epoch: 13 [2500/3276 (38%)]\tLoss: 0.599261\n",
      "Train Epoch: 13 [3000/3276 (46%)]\tLoss: 0.785338\n",
      "\n",
      "Average Train Epoch Loss:  0.6712053698919168\n",
      "Average Train Bin Epoch Loss:  0.16542778311797032\n",
      "Average Train Count Epoch Loss:  0.05076707313518699\n",
      "Average Train Segmentation Epoch Loss:  0.2285505231787882\n",
      "Average Train X-Offset Epoch Loss:  0.15088513984185895\n",
      "Average Train Y-Offset Epoch Loss:  0.0755748452118984\n",
      "Average Validation Epoch Loss:  1.0242309346795082\n",
      "Average Validation Bin Epoch Loss:  0.20840177778154612\n",
      "Average Validation Count Epoch Loss:  0.06160510005429387\n",
      "Average Validation Segmentation Epoch Loss:  0.2869188003242016\n",
      "Average Validation X-Offset Epoch Loss:  0.2624885618686676\n",
      "Average Validation Y-Offset Epoch Loss:  0.2048166796565056\n",
      "Train Epoch: 14 [0/3276 (0%)]\tLoss: 0.645666\n",
      "Train Epoch: 14 [500/3276 (8%)]\tLoss: 0.615368\n",
      "Train Epoch: 14 [1000/3276 (15%)]\tLoss: 0.595628\n",
      "Train Epoch: 14 [1500/3276 (23%)]\tLoss: 0.701662\n",
      "Train Epoch: 14 [2000/3276 (30%)]\tLoss: 0.806461\n",
      "Train Epoch: 14 [2500/3276 (38%)]\tLoss: 0.725354\n",
      "Train Epoch: 14 [3000/3276 (46%)]\tLoss: 0.672739\n",
      "\n",
      "Average Train Epoch Loss:  0.657773496810256\n",
      "Average Train Bin Epoch Loss:  0.16360998149143485\n",
      "Average Train Count Epoch Loss:  0.05031637758834333\n",
      "Average Train Segmentation Epoch Loss:  0.22349113085102745\n",
      "Average Train X-Offset Epoch Loss:  0.14706259329871432\n",
      "Average Train Y-Offset Epoch Loss:  0.07329341104117836\n",
      "Average Validation Epoch Loss:  1.0382472090423107\n",
      "Average Validation Bin Epoch Loss:  0.21161241829395294\n",
      "Average Validation Count Epoch Loss:  0.06451254966668785\n",
      "Average Validation Segmentation Epoch Loss:  0.29414236173033714\n",
      "Average Validation X-Offset Epoch Loss:  0.2650825910270214\n",
      "Average Validation Y-Offset Epoch Loss:  0.20289726555347443\n",
      "Train Epoch: 15 [0/3276 (0%)]\tLoss: 0.621481\n",
      "Train Epoch: 15 [500/3276 (8%)]\tLoss: 0.609201\n",
      "Train Epoch: 15 [1000/3276 (15%)]\tLoss: 0.720123\n",
      "Train Epoch: 15 [1500/3276 (23%)]\tLoss: 0.632838\n",
      "Train Epoch: 15 [2000/3276 (30%)]\tLoss: 0.724487\n",
      "Train Epoch: 15 [2500/3276 (38%)]\tLoss: 0.494047\n",
      "Train Epoch: 15 [3000/3276 (46%)]\tLoss: 0.606956\n",
      "\n",
      "Average Train Epoch Loss:  0.6429758182749515\n",
      "Average Train Bin Epoch Loss:  0.16178298344063322\n",
      "Average Train Count Epoch Loss:  0.04954696184296797\n",
      "Average Train Segmentation Epoch Loss:  0.21730330831757405\n",
      "Average Train X-Offset Epoch Loss:  0.14457723681883114\n",
      "Average Train Y-Offset Epoch Loss:  0.06976532406378083\n",
      "Average Validation Epoch Loss:  1.062450099736452\n",
      "Average Validation Bin Epoch Loss:  0.21082066278904676\n",
      "Average Validation Count Epoch Loss:  0.061884035589173436\n",
      "Average Validation Segmentation Epoch Loss:  0.30848471354693174\n",
      "Average Validation X-Offset Epoch Loss:  0.27297888994216923\n",
      "Average Validation Y-Offset Epoch Loss:  0.20828177928924563\n",
      "Train Epoch: 16 [0/3276 (0%)]\tLoss: 0.740429\n",
      "Train Epoch: 16 [500/3276 (8%)]\tLoss: 0.679535\n",
      "Train Epoch: 16 [1000/3276 (15%)]\tLoss: 0.668886\n",
      "Train Epoch: 16 [1500/3276 (23%)]\tLoss: 0.605723\n",
      "Train Epoch: 16 [2000/3276 (30%)]\tLoss: 0.555290\n",
      "Train Epoch: 16 [2500/3276 (38%)]\tLoss: 0.667001\n",
      "Train Epoch: 16 [3000/3276 (46%)]\tLoss: 0.555071\n",
      "\n",
      "Average Train Epoch Loss:  0.6333182293285684\n",
      "Average Train Bin Epoch Loss:  0.1604908577098352\n",
      "Average Train Count Epoch Loss:  0.049007909009005965\n",
      "Average Train Segmentation Epoch Loss:  0.21271961759321573\n",
      "Average Train X-Offset Epoch Loss:  0.14274856008407547\n",
      "Average Train Y-Offset Epoch Loss:  0.0683512838966236\n",
      "Average Validation Epoch Loss:  1.019044067710638\n",
      "Average Validation Bin Epoch Loss:  0.20838872250169516\n",
      "Average Validation Count Epoch Loss:  0.06105068023316562\n",
      "Average Validation Segmentation Epoch Loss:  0.2804715232923627\n",
      "Average Validation X-Offset Epoch Loss:  0.26959928721189497\n",
      "Average Validation Y-Offset Epoch Loss:  0.19953385144472122\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 17 [0/3276 (0%)]\tLoss: 0.605618\n",
      "Train Epoch: 17 [500/3276 (8%)]\tLoss: 0.723889\n",
      "Train Epoch: 17 [1000/3276 (15%)]\tLoss: 0.729402\n",
      "Train Epoch: 17 [1500/3276 (23%)]\tLoss: 0.522662\n",
      "Train Epoch: 17 [2000/3276 (30%)]\tLoss: 0.621565\n",
      "Train Epoch: 17 [2500/3276 (38%)]\tLoss: 0.712729\n",
      "Train Epoch: 17 [3000/3276 (46%)]\tLoss: 0.529743\n",
      "\n",
      "Average Train Epoch Loss:  0.6185214594915146\n",
      "Average Train Bin Epoch Loss:  0.1585164233224421\n",
      "Average Train Count Epoch Loss:  0.04827019219036873\n",
      "Average Train Segmentation Epoch Loss:  0.20749923677706136\n",
      "Average Train X-Offset Epoch Loss:  0.13965369195836347\n",
      "Average Train Y-Offset Epoch Loss:  0.06458191408253297\n",
      "Average Validation Epoch Loss:  1.0371753610670567\n",
      "Average Validation Bin Epoch Loss:  0.20800682250410318\n",
      "Average Validation Count Epoch Loss:  0.061475571477785707\n",
      "Average Validation Segmentation Epoch Loss:  0.28634096402674913\n",
      "Average Validation X-Offset Epoch Loss:  0.270939813554287\n",
      "Average Validation Y-Offset Epoch Loss:  0.2104121997952461\n",
      "Train Epoch: 18 [0/3276 (0%)]\tLoss: 0.414639\n",
      "Train Epoch: 18 [500/3276 (8%)]\tLoss: 0.569445\n",
      "Train Epoch: 18 [1000/3276 (15%)]\tLoss: 0.675472\n",
      "Train Epoch: 18 [1500/3276 (23%)]\tLoss: 0.533645\n",
      "Train Epoch: 18 [2000/3276 (30%)]\tLoss: 0.536493\n",
      "Train Epoch: 18 [2500/3276 (38%)]\tLoss: 0.590242\n",
      "Train Epoch: 18 [3000/3276 (46%)]\tLoss: 0.549942\n",
      "\n",
      "Average Train Epoch Loss:  0.6089407057478661\n",
      "Average Train Bin Epoch Loss:  0.1573167393756349\n",
      "Average Train Count Epoch Loss:  0.04772988948743881\n",
      "Average Train Segmentation Epoch Loss:  0.20398125141041307\n",
      "Average Train X-Offset Epoch Loss:  0.1375607284467395\n",
      "Average Train Y-Offset Epoch Loss:  0.06235209333187924\n",
      "Average Validation Epoch Loss:  1.0378426983952522\n",
      "Average Validation Bin Epoch Loss:  0.2089984519407153\n",
      "Average Validation Count Epoch Loss:  0.0640559948515147\n",
      "Average Validation Segmentation Epoch Loss:  0.2777325212955475\n",
      "Average Validation X-Offset Epoch Loss:  0.2735822945833206\n",
      "Average Validation Y-Offset Epoch Loss:  0.2134734407067299\n",
      "Train Epoch: 19 [0/3276 (0%)]\tLoss: 0.635427\n",
      "Train Epoch: 19 [500/3276 (8%)]\tLoss: 0.614030\n",
      "Train Epoch: 19 [1000/3276 (15%)]\tLoss: 0.587503\n",
      "Train Epoch: 19 [1500/3276 (23%)]\tLoss: 0.525696\n",
      "Train Epoch: 19 [2000/3276 (30%)]\tLoss: 0.669742\n",
      "Train Epoch: 19 [2500/3276 (38%)]\tLoss: 0.637282\n",
      "Train Epoch: 19 [3000/3276 (46%)]\tLoss: 0.589920\n",
      "\n",
      "Average Train Epoch Loss:  0.5986930280923843\n",
      "Average Train Bin Epoch Loss:  0.15603408619488884\n",
      "Average Train Count Epoch Loss:  0.04760158352735566\n",
      "Average Train Segmentation Epoch Loss:  0.19952404885212097\n",
      "Average Train X-Offset Epoch Loss:  0.1348642627458747\n",
      "Average Train Y-Offset Epoch Loss:  0.06066904312408552\n",
      "Average Validation Epoch Loss:  1.061761848628521\n",
      "Average Validation Bin Epoch Loss:  0.2144269896671176\n",
      "Average Validation Count Epoch Loss:  0.06465019402094185\n",
      "Average Validation Segmentation Epoch Loss:  0.2947210129350424\n",
      "Average Validation X-Offset Epoch Loss:  0.27694311887025835\n",
      "Average Validation Y-Offset Epoch Loss:  0.21102052778005603\n",
      "Train Epoch: 20 [0/3276 (0%)]\tLoss: 0.691172\n",
      "Train Epoch: 20 [500/3276 (8%)]\tLoss: 0.548812\n",
      "Train Epoch: 20 [1000/3276 (15%)]\tLoss: 0.541930\n",
      "Train Epoch: 20 [1500/3276 (23%)]\tLoss: 0.845517\n",
      "Train Epoch: 20 [2000/3276 (30%)]\tLoss: 0.750982\n",
      "Train Epoch: 20 [2500/3276 (38%)]\tLoss: 0.603329\n",
      "Train Epoch: 20 [3000/3276 (46%)]\tLoss: 0.540406\n",
      "\n",
      "Average Train Epoch Loss:  0.590715872805293\n",
      "Average Train Bin Epoch Loss:  0.1547837036593658\n",
      "Average Train Count Epoch Loss:  0.04699397179093666\n",
      "Average Train Segmentation Epoch Loss:  0.19675790784289923\n",
      "Average Train X-Offset Epoch Loss:  0.13227580098844158\n",
      "Average Train Y-Offset Epoch Loss:  0.05990448582281427\n",
      "Average Validation Epoch Loss:  1.012201838195324\n",
      "Average Validation Bin Epoch Loss:  0.20748506765812635\n",
      "Average Validation Count Epoch Loss:  0.06234019924886525\n",
      "Average Validation Segmentation Epoch Loss:  0.2712448872625828\n",
      "Average Validation X-Offset Epoch Loss:  0.27163059115409854\n",
      "Average Validation Y-Offset Epoch Loss:  0.19950108751654627\n",
      "Train Epoch: 21 [0/3276 (0%)]\tLoss: 0.614911\n",
      "Train Epoch: 21 [500/3276 (8%)]\tLoss: 0.655782\n",
      "Train Epoch: 21 [1000/3276 (15%)]\tLoss: 0.483534\n",
      "Train Epoch: 21 [1500/3276 (23%)]\tLoss: 0.583111\n",
      "Train Epoch: 21 [2000/3276 (30%)]\tLoss: 0.708767\n",
      "Train Epoch: 21 [2500/3276 (38%)]\tLoss: 0.530083\n",
      "Train Epoch: 21 [3000/3276 (46%)]\tLoss: 0.549378\n",
      "\n",
      "Average Train Epoch Loss:  0.5830510079678966\n",
      "Average Train Bin Epoch Loss:  0.15337995623760833\n",
      "Average Train Count Epoch Loss:  0.046457760751519986\n",
      "Average Train Segmentation Epoch Loss:  0.19366882025922943\n",
      "Average Train X-Offset Epoch Loss:  0.13131712744148766\n",
      "Average Train Y-Offset Epoch Loss:  0.058227342285397575\n",
      "Average Validation Epoch Loss:  1.0198253653943539\n",
      "Average Validation Bin Epoch Loss:  0.2040732391178608\n",
      "Average Validation Count Epoch Loss:  0.06312144175171852\n",
      "Average Validation Segmentation Epoch Loss:  0.27160336542874575\n",
      "Average Validation X-Offset Epoch Loss:  0.2712386377155781\n",
      "Average Validation Y-Offset Epoch Loss:  0.20978867039084437\n",
      "Train Epoch: 22 [0/3276 (0%)]\tLoss: 0.593400\n",
      "Train Epoch: 22 [500/3276 (8%)]\tLoss: 0.556416\n",
      "Train Epoch: 22 [1000/3276 (15%)]\tLoss: 0.515498\n",
      "Train Epoch: 22 [1500/3276 (23%)]\tLoss: 0.538817\n",
      "Train Epoch: 22 [2000/3276 (30%)]\tLoss: 0.625076\n",
      "Train Epoch: 22 [2500/3276 (38%)]\tLoss: 0.577345\n",
      "Train Epoch: 22 [3000/3276 (46%)]\tLoss: 0.521753\n",
      "\n",
      "Average Train Epoch Loss:  0.5674836349378272\n",
      "Average Train Bin Epoch Loss:  0.15164021793298604\n",
      "Average Train Count Epoch Loss:  0.04576464130247875\n",
      "Average Train Segmentation Epoch Loss:  0.18842929240497874\n",
      "Average Train X-Offset Epoch Loss:  0.1259835748592528\n",
      "Average Train Y-Offset Epoch Loss:  0.05566590523756132\n",
      "Average Validation Epoch Loss:  1.0300723500549793\n",
      "Average Validation Bin Epoch Loss:  0.20784886181354523\n",
      "Average Validation Count Epoch Loss:  0.06412516464479268\n",
      "Average Validation Segmentation Epoch Loss:  0.2695732554420829\n",
      "Average Validation X-Offset Epoch Loss:  0.27385206073522567\n",
      "Average Validation Y-Offset Epoch Loss:  0.2146729789674282\n",
      "Train Epoch: 23 [0/3276 (0%)]\tLoss: 0.595853\n",
      "Train Epoch: 23 [500/3276 (8%)]\tLoss: 0.518161\n",
      "Train Epoch: 23 [1000/3276 (15%)]\tLoss: 0.422797\n",
      "Train Epoch: 23 [1500/3276 (23%)]\tLoss: 0.542928\n",
      "Train Epoch: 23 [2000/3276 (30%)]\tLoss: 0.475029\n",
      "Train Epoch: 23 [2500/3276 (38%)]\tLoss: 0.640676\n",
      "Train Epoch: 23 [3000/3276 (46%)]\tLoss: 0.568971\n",
      "\n",
      "Average Train Epoch Loss:  0.5622980839050398\n",
      "Average Train Bin Epoch Loss:  0.15074351061953278\n",
      "Average Train Count Epoch Loss:  0.04540593268508773\n",
      "Average Train Segmentation Epoch Loss:  0.18657857724806157\n",
      "Average Train X-Offset Epoch Loss:  0.12545000394669975\n",
      "Average Train Y-Offset Epoch Loss:  0.05412005636295895\n",
      "Average Validation Epoch Loss:  1.00125065818429\n",
      "Average Validation Bin Epoch Loss:  0.20165135152637959\n",
      "Average Validation Count Epoch Loss:  0.062136291060596704\n",
      "Average Validation Segmentation Epoch Loss:  0.25524988770484924\n",
      "Average Validation X-Offset Epoch Loss:  0.2776266381144524\n",
      "Average Validation Y-Offset Epoch Loss:  0.20458647534251212\n",
      "Train Epoch: 24 [0/3276 (0%)]\tLoss: 0.565465\n",
      "Train Epoch: 24 [500/3276 (8%)]\tLoss: 0.711515\n",
      "Train Epoch: 24 [1000/3276 (15%)]\tLoss: 0.566319\n",
      "Train Epoch: 24 [1500/3276 (23%)]\tLoss: 0.559163\n",
      "Train Epoch: 24 [2000/3276 (30%)]\tLoss: 0.592083\n",
      "Train Epoch: 24 [2500/3276 (38%)]\tLoss: 0.490197\n",
      "Train Epoch: 24 [3000/3276 (46%)]\tLoss: 0.651767\n",
      "\n",
      "Average Train Epoch Loss:  0.5544204802774801\n",
      "Average Train Bin Epoch Loss:  0.14951265728237426\n",
      "Average Train Count Epoch Loss:  0.044810351228523185\n",
      "Average Train Segmentation Epoch Loss:  0.18466170570563253\n",
      "Average Train X-Offset Epoch Loss:  0.12189434695898033\n",
      "Average Train Y-Offset Epoch Loss:  0.05354141566175514\n",
      "Average Validation Epoch Loss:  1.0042535662651062\n",
      "Average Validation Bin Epoch Loss:  0.2021520473062992\n",
      "Average Validation Count Epoch Loss:  0.06307480833493173\n",
      "Average Validation Segmentation Epoch Loss:  0.2559870658442378\n",
      "Average Validation X-Offset Epoch Loss:  0.2820596009492874\n",
      "Average Validation Y-Offset Epoch Loss:  0.2009800285100937\n",
      "Train Epoch: 25 [0/3276 (0%)]\tLoss: 0.645387\n",
      "Train Epoch: 25 [500/3276 (8%)]\tLoss: 0.481438\n",
      "Train Epoch: 25 [1000/3276 (15%)]\tLoss: 0.452240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 25 [1500/3276 (23%)]\tLoss: 0.450068\n",
      "Train Epoch: 25 [2000/3276 (30%)]\tLoss: 0.507724\n",
      "Train Epoch: 25 [2500/3276 (38%)]\tLoss: 0.440036\n",
      "Train Epoch: 25 [3000/3276 (46%)]\tLoss: 0.570038\n",
      "\n",
      "Average Train Epoch Loss:  0.5468076815510668\n",
      "Average Train Bin Epoch Loss:  0.14865542305406274\n",
      "Average Train Count Epoch Loss:  0.04455997780669571\n",
      "Average Train Segmentation Epoch Loss:  0.18175021988317008\n",
      "Average Train X-Offset Epoch Loss:  0.11955531642931264\n",
      "Average Train Y-Offset Epoch Loss:  0.05228674100121347\n",
      "Average Validation Epoch Loss:  1.0199095383286476\n",
      "Average Validation Bin Epoch Loss:  0.20236483868211508\n",
      "Average Validation Count Epoch Loss:  0.06364919990301132\n",
      "Average Validation Segmentation Epoch Loss:  0.2582975560799241\n",
      "Average Validation X-Offset Epoch Loss:  0.2790671713650227\n",
      "Average Validation Y-Offset Epoch Loss:  0.21653076559305193\n",
      "Train Epoch: 26 [0/3276 (0%)]\tLoss: 0.586692\n",
      "Train Epoch: 26 [500/3276 (8%)]\tLoss: 0.500722\n",
      "Train Epoch: 26 [1000/3276 (15%)]\tLoss: 0.559366\n",
      "Train Epoch: 26 [1500/3276 (23%)]\tLoss: 0.515096\n",
      "Train Epoch: 26 [2000/3276 (30%)]\tLoss: 0.483288\n",
      "Train Epoch: 26 [2500/3276 (38%)]\tLoss: 0.494523\n",
      "Train Epoch: 26 [3000/3276 (46%)]\tLoss: 0.560714\n",
      "\n",
      "Average Train Epoch Loss:  0.5393710467146664\n",
      "Average Train Bin Epoch Loss:  0.14772005869847973\n",
      "Average Train Count Epoch Loss:  0.04435163810167734\n",
      "Average Train Segmentation Epoch Loss:  0.1780326544738761\n",
      "Average Train X-Offset Epoch Loss:  0.11792136845065328\n",
      "Average Train Y-Offset Epoch Loss:  0.05134532459807105\n",
      "Average Validation Epoch Loss:  1.0211762934923172\n",
      "Average Validation Bin Epoch Loss:  0.20144123397767544\n",
      "Average Validation Count Epoch Loss:  0.06440776493400335\n",
      "Average Validation Segmentation Epoch Loss:  0.2567856516689062\n",
      "Average Validation X-Offset Epoch Loss:  0.282527269423008\n",
      "Average Validation Y-Offset Epoch Loss:  0.2160143800079823\n",
      "Train Epoch: 27 [0/3276 (0%)]\tLoss: 0.625665\n",
      "Train Epoch: 27 [500/3276 (8%)]\tLoss: 0.438188\n",
      "Train Epoch: 27 [1000/3276 (15%)]\tLoss: 0.494124\n",
      "Train Epoch: 27 [1500/3276 (23%)]\tLoss: 0.580931\n",
      "Train Epoch: 27 [2000/3276 (30%)]\tLoss: 0.390327\n",
      "Train Epoch: 27 [2500/3276 (38%)]\tLoss: 0.545103\n",
      "Train Epoch: 27 [3000/3276 (46%)]\tLoss: 0.416066\n",
      "\n",
      "Average Train Epoch Loss:  0.5315549310024191\n",
      "Average Train Bin Epoch Loss:  0.14613530968838348\n",
      "Average Train Count Epoch Loss:  0.04365741950459778\n",
      "Average Train Segmentation Epoch Loss:  0.17600582063016368\n",
      "Average Train X-Offset Epoch Loss:  0.11501223134194934\n",
      "Average Train Y-Offset Epoch Loss:  0.05074414660381835\n",
      "Average Validation Epoch Loss:  1.0203749649226665\n",
      "Average Validation Bin Epoch Loss:  0.20284464303404093\n",
      "Average Validation Count Epoch Loss:  0.06419736077077687\n",
      "Average Validation Segmentation Epoch Loss:  0.26154056284576654\n",
      "Average Validation X-Offset Epoch Loss:  0.2821526855230332\n",
      "Average Validation Y-Offset Epoch Loss:  0.20963970571756363\n",
      "Train Epoch: 28 [0/3276 (0%)]\tLoss: 0.606582\n",
      "Train Epoch: 28 [500/3276 (8%)]\tLoss: 0.506087\n",
      "Train Epoch: 28 [1000/3276 (15%)]\tLoss: 0.495271\n",
      "Train Epoch: 28 [1500/3276 (23%)]\tLoss: 0.666852\n",
      "Train Epoch: 28 [2000/3276 (30%)]\tLoss: 0.539213\n",
      "Train Epoch: 28 [2500/3276 (38%)]\tLoss: 0.546746\n",
      "\n",
      "Average Train Epoch Loss:  0.525822295193992\n",
      "Average Train Bin Epoch Loss:  0.1450893680178901\n",
      "Average Train Count Epoch Loss:  0.043070901111449775\n",
      "Average Train Segmentation Epoch Loss:  0.1741893523395425\n",
      "Average Train X-Offset Epoch Loss:  0.11388608691532438\n",
      "Average Train Y-Offset Epoch Loss:  0.04958658591821427\n",
      "Average Validation Epoch Loss:  1.0228250995278358\n",
      "Average Validation Bin Epoch Loss:  0.2057072976604104\n",
      "Average Validation Count Epoch Loss:  0.06492240820080042\n",
      "Average Validation Segmentation Epoch Loss:  0.2600678587332368\n",
      "Average Validation X-Offset Epoch Loss:  0.2844513304531574\n",
      "Average Validation Y-Offset Epoch Loss:  0.20767619684338573\n",
      "Train Epoch: 29 [0/3276 (0%)]\tLoss: 0.458229\n",
      "Train Epoch: 29 [500/3276 (8%)]\tLoss: 0.449699\n",
      "Train Epoch: 29 [1000/3276 (15%)]\tLoss: 0.547860\n",
      "Train Epoch: 29 [1500/3276 (23%)]\tLoss: 0.581330\n",
      "Train Epoch: 29 [2000/3276 (30%)]\tLoss: 0.522730\n",
      "Train Epoch: 29 [2500/3276 (38%)]\tLoss: 0.441748\n",
      "Train Epoch: 29 [3000/3276 (46%)]\tLoss: 0.466760\n",
      "\n",
      "Average Train Epoch Loss:  0.5201384963967451\n",
      "Average Train Bin Epoch Loss:  0.14420901436540412\n",
      "Average Train Count Epoch Loss:  0.04275666401585246\n",
      "Average Train Segmentation Epoch Loss:  0.17264128647880947\n",
      "Average Train X-Offset Epoch Loss:  0.1123208795378848\n",
      "Average Train Y-Offset Epoch Loss:  0.04821065005551024\n",
      "Average Validation Epoch Loss:  1.056002639234066\n",
      "Average Validation Bin Epoch Loss:  0.20909389201551676\n",
      "Average Validation Count Epoch Loss:  0.0669718855060637\n",
      "Average Validation Segmentation Epoch Loss:  0.2817744519561529\n",
      "Average Validation X-Offset Epoch Loss:  0.28619363307952883\n",
      "Average Validation Y-Offset Epoch Loss:  0.21196878775954248\n",
      "Train Epoch: 30 [0/3276 (0%)]\tLoss: 0.588800\n",
      "Train Epoch: 30 [500/3276 (8%)]\tLoss: 0.419272\n",
      "Train Epoch: 30 [1000/3276 (15%)]\tLoss: 0.534283\n",
      "Train Epoch: 30 [1500/3276 (23%)]\tLoss: 0.719872\n",
      "Train Epoch: 30 [2000/3276 (30%)]\tLoss: 0.413092\n",
      "Train Epoch: 30 [2500/3276 (38%)]\tLoss: 0.537773\n",
      "Train Epoch: 30 [3000/3276 (46%)]\tLoss: 0.391896\n",
      "\n",
      "Average Train Epoch Loss:  0.5117716122327781\n",
      "Average Train Bin Epoch Loss:  0.14325313204217974\n",
      "Average Train Count Epoch Loss:  0.042409191447560016\n",
      "Average Train Segmentation Epoch Loss:  0.1703893902779716\n",
      "Average Train X-Offset Epoch Loss:  0.10876495162161387\n",
      "Average Train Y-Offset Epoch Loss:  0.046954944807036623\n",
      "Average Validation Epoch Loss:  1.0367102660238743\n",
      "Average Validation Bin Epoch Loss:  0.2074736412614584\n",
      "Average Validation Count Epoch Loss:  0.06215370213612914\n",
      "Average Validation Segmentation Epoch Loss:  0.26862364262342453\n",
      "Average Validation X-Offset Epoch Loss:  0.2921007052063942\n",
      "Average Validation Y-Offset Epoch Loss:  0.2063585877418518\n",
      "Train Epoch: 31 [0/3276 (0%)]\tLoss: 0.627488\n",
      "Train Epoch: 31 [500/3276 (8%)]\tLoss: 0.482582\n",
      "Train Epoch: 31 [1000/3276 (15%)]\tLoss: 0.424000\n",
      "Train Epoch: 31 [1500/3276 (23%)]\tLoss: 0.520266\n",
      "Train Epoch: 31 [2000/3276 (30%)]\tLoss: 0.542761\n",
      "Train Epoch: 31 [2500/3276 (38%)]\tLoss: 0.372936\n",
      "Train Epoch: 31 [3000/3276 (46%)]\tLoss: 0.531052\n",
      "\n",
      "Average Train Epoch Loss:  0.5067228484989666\n",
      "Average Train Bin Epoch Loss:  0.14240579402483092\n",
      "Average Train Count Epoch Loss:  0.04190418685263977\n",
      "Average Train Segmentation Epoch Loss:  0.16860130274804627\n",
      "Average Train X-Offset Epoch Loss:  0.10712742818201461\n",
      "Average Train Y-Offset Epoch Loss:  0.0466841358328011\n",
      "Average Validation Epoch Loss:  1.0476226843893528\n",
      "Average Validation Bin Epoch Loss:  0.20445054583251476\n",
      "Average Validation Count Epoch Loss:  0.06664992030709982\n",
      "Average Validation Segmentation Epoch Loss:  0.2653766768053174\n",
      "Average Validation X-Offset Epoch Loss:  0.29013017863035206\n",
      "Average Validation Y-Offset Epoch Loss:  0.22101533934473994\n",
      "Train Epoch: 32 [0/3276 (0%)]\tLoss: 0.484004\n",
      "Train Epoch: 32 [500/3276 (8%)]\tLoss: 0.569945\n",
      "Train Epoch: 32 [1000/3276 (15%)]\tLoss: 0.573338\n",
      "Train Epoch: 32 [1500/3276 (23%)]\tLoss: 0.507533\n",
      "Train Epoch: 32 [2000/3276 (30%)]\tLoss: 0.472184\n",
      "Train Epoch: 32 [2500/3276 (38%)]\tLoss: 0.446782\n",
      "Train Epoch: 32 [3000/3276 (46%)]\tLoss: 0.346017\n",
      "\n",
      "Average Train Epoch Loss:  0.5023134956817802\n",
      "Average Train Bin Epoch Loss:  0.14158111819770278\n",
      "Average Train Count Epoch Loss:  0.041416908540513095\n",
      "Average Train Segmentation Epoch Loss:  0.16679510808118234\n",
      "Average Train X-Offset Epoch Loss:  0.10674039932285868\n",
      "Average Train Y-Offset Epoch Loss:  0.0457799601482182\n",
      "Average Validation Epoch Loss:  1.0281406976282597\n",
      "Average Validation Bin Epoch Loss:  0.20298369601368904\n",
      "Average Validation Count Epoch Loss:  0.06483079981990159\n",
      "Average Validation Segmentation Epoch Loss:  0.2502338159829378\n",
      "Average Validation X-Offset Epoch Loss:  0.2898430824279785\n",
      "Average Validation Y-Offset Epoch Loss:  0.22024927213788031\n",
      "Train Epoch: 33 [0/3276 (0%)]\tLoss: 0.478317\n",
      "Train Epoch: 33 [500/3276 (8%)]\tLoss: 0.412680\n",
      "Train Epoch: 33 [1000/3276 (15%)]\tLoss: 0.497769\n",
      "Train Epoch: 33 [1500/3276 (23%)]\tLoss: 0.468157\n",
      "Train Epoch: 33 [2000/3276 (30%)]\tLoss: 0.514135\n",
      "Train Epoch: 33 [2500/3276 (38%)]\tLoss: 0.599368\n",
      "Train Epoch: 33 [3000/3276 (46%)]\tLoss: 0.560691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Train Epoch Loss:  0.49743718853810936\n",
      "Average Train Bin Epoch Loss:  0.14111690793368148\n",
      "Average Train Count Epoch Loss:  0.04114723041449196\n",
      "Average Train Segmentation Epoch Loss:  0.16493866758466494\n",
      "Average Train X-Offset Epoch Loss:  0.10460024363384014\n",
      "Average Train Y-Offset Epoch Loss:  0.04563413666243233\n",
      "Average Validation Epoch Loss:  1.001634493470192\n",
      "Average Validation Bin Epoch Loss:  0.20386551227420568\n",
      "Average Validation Count Epoch Loss:  0.0624683138448745\n",
      "Average Validation Segmentation Epoch Loss:  0.24750246945768595\n",
      "Average Validation X-Offset Epoch Loss:  0.28826966136693954\n",
      "Average Validation Y-Offset Epoch Loss:  0.1995285153388977\n",
      "Train Epoch: 34 [0/3276 (0%)]\tLoss: 0.368277\n",
      "Train Epoch: 34 [500/3276 (8%)]\tLoss: 0.593633\n",
      "Train Epoch: 34 [1000/3276 (15%)]\tLoss: 0.528548\n",
      "Train Epoch: 34 [1500/3276 (23%)]\tLoss: 0.515859\n",
      "Train Epoch: 34 [2000/3276 (30%)]\tLoss: 0.521510\n",
      "Train Epoch: 34 [2500/3276 (38%)]\tLoss: 0.570472\n",
      "Train Epoch: 34 [3000/3276 (46%)]\tLoss: 0.477978\n",
      "\n",
      "Average Train Epoch Loss:  0.49236685201162245\n",
      "Average Train Bin Epoch Loss:  0.1403407333191575\n",
      "Average Train Count Epoch Loss:  0.040820929806724915\n",
      "Average Train Segmentation Epoch Loss:  0.16303654977052315\n",
      "Average Train X-Offset Epoch Loss:  0.10339618961258634\n",
      "Average Train Y-Offset Epoch Loss:  0.04477244785918695\n",
      "Average Validation Epoch Loss:  1.0121523700654507\n",
      "Average Validation Bin Epoch Loss:  0.20483556110411882\n",
      "Average Validation Count Epoch Loss:  0.06396732130087912\n",
      "Average Validation Segmentation Epoch Loss:  0.2503015296533704\n",
      "Average Validation X-Offset Epoch Loss:  0.28784986585378647\n",
      "Average Validation Y-Offset Epoch Loss:  0.2051980741322041\n",
      "Train Epoch: 35 [0/3276 (0%)]\tLoss: 0.441163\n",
      "Train Epoch: 35 [500/3276 (8%)]\tLoss: 0.462569\n",
      "Train Epoch: 35 [1000/3276 (15%)]\tLoss: 0.429313\n",
      "Train Epoch: 35 [1500/3276 (23%)]\tLoss: 0.600273\n",
      "Train Epoch: 35 [2000/3276 (30%)]\tLoss: 0.486809\n",
      "Train Epoch: 35 [2500/3276 (38%)]\tLoss: 0.503896\n",
      "Train Epoch: 35 [3000/3276 (46%)]\tLoss: 0.479225\n",
      "\n",
      "Average Train Epoch Loss:  0.4884267090479048\n",
      "Average Train Bin Epoch Loss:  0.13958210429949006\n",
      "Average Train Count Epoch Loss:  0.0405032516161843\n",
      "Average Train Segmentation Epoch Loss:  0.162535104219143\n",
      "Average Train X-Offset Epoch Loss:  0.10178317046020091\n",
      "Average Train Y-Offset Epoch Loss:  0.044023076540268054\n",
      "Average Validation Epoch Loss:  1.00435471534729\n",
      "Average Validation Bin Epoch Loss:  0.20235320646315813\n",
      "Average Validation Count Epoch Loss:  0.0625695395283401\n",
      "Average Validation Segmentation Epoch Loss:  0.24649203848093748\n",
      "Average Validation X-Offset Epoch Loss:  0.2833342581987381\n",
      "Average Validation Y-Offset Epoch Loss:  0.2096056580543518\n",
      "Train Epoch: 36 [0/3276 (0%)]\tLoss: 0.551314\n",
      "Train Epoch: 36 [500/3276 (8%)]\tLoss: 0.617177\n",
      "Train Epoch: 36 [1000/3276 (15%)]\tLoss: 0.594123\n",
      "Train Epoch: 36 [1500/3276 (23%)]\tLoss: 0.565227\n",
      "Train Epoch: 36 [2000/3276 (30%)]\tLoss: 0.559385\n",
      "Train Epoch: 36 [2500/3276 (38%)]\tLoss: 0.439523\n",
      "Train Epoch: 36 [3000/3276 (46%)]\tLoss: 0.436075\n",
      "\n",
      "Average Train Epoch Loss:  0.48311943215567893\n",
      "Average Train Bin Epoch Loss:  0.13873017236317803\n",
      "Average Train Count Epoch Loss:  0.040060952243327\n",
      "Average Train Segmentation Epoch Loss:  0.1605470614939383\n",
      "Average Train X-Offset Epoch Loss:  0.0995729581793634\n",
      "Average Train Y-Offset Epoch Loss:  0.04420828386777785\n",
      "Average Validation Epoch Loss:  1.0011692084372044\n",
      "Average Validation Bin Epoch Loss:  0.20271070580929518\n",
      "Average Validation Count Epoch Loss:  0.06467389571480453\n",
      "Average Validation Segmentation Epoch Loss:  0.24355159420520067\n",
      "Average Validation X-Offset Epoch Loss:  0.2859618842601776\n",
      "Average Validation Y-Offset Epoch Loss:  0.2042711041867733\n",
      "Train Epoch: 37 [0/3276 (0%)]\tLoss: 0.431229\n",
      "Train Epoch: 37 [500/3276 (8%)]\tLoss: 0.440795\n",
      "Train Epoch: 37 [1000/3276 (15%)]\tLoss: 0.518604\n",
      "Train Epoch: 37 [1500/3276 (23%)]\tLoss: 0.394089\n",
      "Train Epoch: 37 [2000/3276 (30%)]\tLoss: 0.545326\n",
      "Train Epoch: 37 [2500/3276 (38%)]\tLoss: 0.437743\n",
      "Train Epoch: 37 [3000/3276 (46%)]\tLoss: 0.545484\n",
      "\n",
      "Average Train Epoch Loss:  0.47812019497519587\n",
      "Average Train Bin Epoch Loss:  0.13767032061771647\n",
      "Average Train Count Epoch Loss:  0.03993610451111525\n",
      "Average Train Segmentation Epoch Loss:  0.15927346105255732\n",
      "Average Train X-Offset Epoch Loss:  0.09834705614825576\n",
      "Average Train Y-Offset Epoch Loss:  0.04289325133602067\n",
      "Average Validation Epoch Loss:  1.0229755826294422\n",
      "Average Validation Bin Epoch Loss:  0.20320796687155962\n",
      "Average Validation Count Epoch Loss:  0.06554683204740286\n",
      "Average Validation Segmentation Epoch Loss:  0.2514832569286227\n",
      "Average Validation X-Offset Epoch Loss:  0.29085724949836733\n",
      "Average Validation Y-Offset Epoch Loss:  0.21188025772571564\n",
      "Train Epoch: 38 [0/3276 (0%)]\tLoss: 0.449531\n",
      "Train Epoch: 38 [500/3276 (8%)]\tLoss: 0.435155\n",
      "Train Epoch: 38 [1000/3276 (15%)]\tLoss: 0.531651\n",
      "Train Epoch: 38 [1500/3276 (23%)]\tLoss: 0.519419\n",
      "Train Epoch: 38 [2000/3276 (30%)]\tLoss: 0.527542\n",
      "Train Epoch: 38 [2500/3276 (38%)]\tLoss: 0.406629\n",
      "Train Epoch: 38 [3000/3276 (46%)]\tLoss: 0.391706\n",
      "\n",
      "Average Train Epoch Loss:  0.47644760786760143\n",
      "Average Train Bin Epoch Loss:  0.13743421687494692\n",
      "Average Train Count Epoch Loss:  0.039645155443151184\n",
      "Average Train Segmentation Epoch Loss:  0.15888198833094863\n",
      "Average Train X-Offset Epoch Loss:  0.09751701325905032\n",
      "Average Train Y-Offset Epoch Loss:  0.04296923034892577\n",
      "Average Validation Epoch Loss:  1.0090934224426746\n",
      "Average Validation Bin Epoch Loss:  0.2037529656663537\n",
      "Average Validation Count Epoch Loss:  0.06553015299141407\n",
      "Average Validation Segmentation Epoch Loss:  0.24618968646973372\n",
      "Average Validation X-Offset Epoch Loss:  0.2895029276609421\n",
      "Average Validation Y-Offset Epoch Loss:  0.20411767438054085\n",
      "Train Epoch: 39 [0/3276 (0%)]\tLoss: 0.403863\n",
      "Train Epoch: 39 [500/3276 (8%)]\tLoss: 0.511364\n",
      "Train Epoch: 39 [1000/3276 (15%)]\tLoss: 0.396445\n",
      "Train Epoch: 39 [1500/3276 (23%)]\tLoss: 0.489354\n",
      "Train Epoch: 39 [2000/3276 (30%)]\tLoss: 0.478428\n",
      "Train Epoch: 39 [2500/3276 (38%)]\tLoss: 0.397723\n",
      "Train Epoch: 39 [3000/3276 (46%)]\tLoss: 0.481534\n",
      "\n",
      "Average Train Epoch Loss:  0.4734718833209538\n",
      "Average Train Bin Epoch Loss:  0.1373909993960363\n",
      "Average Train Count Epoch Loss:  0.03939706712347887\n",
      "Average Train Segmentation Epoch Loss:  0.15747007009823147\n",
      "Average Train X-Offset Epoch Loss:  0.09658915644011848\n",
      "Average Train Y-Offset Epoch Loss:  0.04262458661162272\n",
      "Average Validation Epoch Loss:  1.0293493568897247\n",
      "Average Validation Bin Epoch Loss:  0.20663866121321917\n",
      "Average Validation Count Epoch Loss:  0.06811113865114748\n",
      "Average Validation Segmentation Epoch Loss:  0.25648574251681566\n",
      "Average Validation X-Offset Epoch Loss:  0.2918466985225678\n",
      "Average Validation Y-Offset Epoch Loss:  0.20626709014177325\n",
      "Train Epoch: 40 [0/3276 (0%)]\tLoss: 0.607866\n",
      "Train Epoch: 40 [500/3276 (8%)]\tLoss: 0.432398\n",
      "Train Epoch: 40 [1000/3276 (15%)]\tLoss: 0.427821\n",
      "Train Epoch: 40 [1500/3276 (23%)]\tLoss: 0.541208\n",
      "Train Epoch: 40 [2000/3276 (30%)]\tLoss: 0.347555\n",
      "Train Epoch: 40 [2500/3276 (38%)]\tLoss: 0.366272\n",
      "Train Epoch: 40 [3000/3276 (46%)]\tLoss: 0.651990\n",
      "\n",
      "Average Train Epoch Loss:  0.4664371201723087\n",
      "Average Train Bin Epoch Loss:  0.13635071233005785\n",
      "Average Train Count Epoch Loss:  0.039013093070513226\n",
      "Average Train Segmentation Epoch Loss:  0.15562015903613916\n",
      "Average Train X-Offset Epoch Loss:  0.09394820401581323\n",
      "Average Train Y-Offset Epoch Loss:  0.04150494926313802\n",
      "Average Validation Epoch Loss:  1.0074757933616638\n",
      "Average Validation Bin Epoch Loss:  0.20336236152797937\n",
      "Average Validation Count Epoch Loss:  0.06497799698263407\n",
      "Average Validation Segmentation Epoch Loss:  0.24500213377177715\n",
      "Average Validation X-Offset Epoch Loss:  0.2856536000967026\n",
      "Average Validation Y-Offset Epoch Loss:  0.20847968459129335\n",
      "Train Epoch: 41 [0/3276 (0%)]\tLoss: 0.448465\n",
      "Train Epoch: 41 [500/3276 (8%)]\tLoss: 0.466072\n",
      "Train Epoch: 41 [1000/3276 (15%)]\tLoss: 0.407788\n",
      "Train Epoch: 41 [1500/3276 (23%)]\tLoss: 0.402433\n",
      "Train Epoch: 41 [2000/3276 (30%)]\tLoss: 0.375728\n",
      "Train Epoch: 41 [2500/3276 (38%)]\tLoss: 0.391224\n",
      "Train Epoch: 41 [3000/3276 (46%)]\tLoss: 0.561085\n",
      "\n",
      "Average Train Epoch Loss:  0.46294970165302113\n",
      "Average Train Bin Epoch Loss:  0.13539536151944137\n",
      "Average Train Count Epoch Loss:  0.03875466490664133\n",
      "Average Train Segmentation Epoch Loss:  0.15396059188628342\n",
      "Average Train X-Offset Epoch Loss:  0.09393334913907982\n",
      "Average Train Y-Offset Epoch Loss:  0.04090573163021628\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Validation Epoch Loss:  0.9938587732613087\n",
      "Average Validation Bin Epoch Loss:  0.20582658145576715\n",
      "Average Validation Count Epoch Loss:  0.0633002535905689\n",
      "Average Validation Segmentation Epoch Loss:  0.23465562798082829\n",
      "Average Validation X-Offset Epoch Loss:  0.28257910013198856\n",
      "Average Validation Y-Offset Epoch Loss:  0.20749722570180895\n",
      "Train Epoch: 42 [0/3276 (0%)]\tLoss: 0.414681\n",
      "Train Epoch: 42 [500/3276 (8%)]\tLoss: 0.423672\n",
      "Train Epoch: 42 [1000/3276 (15%)]\tLoss: 0.394427\n",
      "Train Epoch: 42 [1500/3276 (23%)]\tLoss: 0.463043\n",
      "Train Epoch: 42 [2000/3276 (30%)]\tLoss: 0.551949\n",
      "Train Epoch: 42 [2500/3276 (38%)]\tLoss: 0.452005\n",
      "Train Epoch: 42 [3000/3276 (46%)]\tLoss: 0.444631\n",
      "\n",
      "Average Train Epoch Loss:  0.4616292448850667\n",
      "Average Train Bin Epoch Loss:  0.13550186307146783\n",
      "Average Train Count Epoch Loss:  0.03872305361508596\n",
      "Average Train Segmentation Epoch Loss:  0.1543143324599397\n",
      "Average Train X-Offset Epoch Loss:  0.09246364161372185\n",
      "Average Train Y-Offset Epoch Loss:  0.04062635261202004\n",
      "Average Validation Epoch Loss:  1.0488785915076733\n",
      "Average Validation Bin Epoch Loss:  0.20588362775743008\n",
      "Average Validation Count Epoch Loss:  0.06711031217128038\n",
      "Average Validation Segmentation Epoch Loss:  0.2649564817547798\n",
      "Average Validation X-Offset Epoch Loss:  0.2935963347554207\n",
      "Average Validation Y-Offset Epoch Loss:  0.21733180657029152\n",
      "Train Epoch: 43 [0/3276 (0%)]\tLoss: 0.516986\n",
      "Train Epoch: 43 [500/3276 (8%)]\tLoss: 0.440398\n",
      "Train Epoch: 43 [1000/3276 (15%)]\tLoss: 0.571332\n",
      "Train Epoch: 43 [1500/3276 (23%)]\tLoss: 0.415255\n",
      "Train Epoch: 43 [2000/3276 (30%)]\tLoss: 0.463093\n",
      "Train Epoch: 43 [2500/3276 (38%)]\tLoss: 0.364416\n",
      "Train Epoch: 43 [3000/3276 (46%)]\tLoss: 0.378402\n",
      "\n",
      "Average Train Epoch Loss:  0.45682397239455363\n",
      "Average Train Bin Epoch Loss:  0.13457735634704188\n",
      "Average Train Count Epoch Loss:  0.03817652454372586\n",
      "Average Train Segmentation Epoch Loss:  0.15271647860545937\n",
      "Average Train X-Offset Epoch Loss:  0.09120295900942349\n",
      "Average Train Y-Offset Epoch Loss:  0.04015065122214032\n",
      "Average Validation Epoch Loss:  1.0235610119998455\n",
      "Average Validation Bin Epoch Loss:  0.20275165047496557\n",
      "Average Validation Count Epoch Loss:  0.06495856470428407\n",
      "Average Validation Segmentation Epoch Loss:  0.24704052694141865\n",
      "Average Validation X-Offset Epoch Loss:  0.2960848152637482\n",
      "Average Validation Y-Offset Epoch Loss:  0.2127254642546177\n",
      "Train Epoch: 44 [0/3276 (0%)]\tLoss: 0.406115\n",
      "Train Epoch: 44 [500/3276 (8%)]\tLoss: 0.443549\n",
      "Train Epoch: 44 [1000/3276 (15%)]\tLoss: 0.527343\n",
      "Train Epoch: 44 [1500/3276 (23%)]\tLoss: 0.440829\n",
      "Train Epoch: 44 [2000/3276 (30%)]\tLoss: 0.512947\n",
      "Train Epoch: 44 [2500/3276 (38%)]\tLoss: 0.459405\n",
      "Train Epoch: 44 [3000/3276 (46%)]\tLoss: 0.494563\n",
      "\n",
      "Average Train Epoch Loss:  0.4528516550071356\n",
      "Average Train Bin Epoch Loss:  0.133712395207911\n",
      "Average Train Count Epoch Loss:  0.038057303544497344\n",
      "Average Train Segmentation Epoch Loss:  0.15090198131141866\n",
      "Average Train X-Offset Epoch Loss:  0.0901900137979083\n",
      "Average Train Y-Offset Epoch Loss:  0.03998995990742271\n",
      "Average Validation Epoch Loss:  1.015352040529251\n",
      "Average Validation Bin Epoch Loss:  0.20302212610840797\n",
      "Average Validation Count Epoch Loss:  0.06202600710093975\n",
      "Average Validation Segmentation Epoch Loss:  0.24550419952720404\n",
      "Average Validation X-Offset Epoch Loss:  0.29886722862720494\n",
      "Average Validation Y-Offset Epoch Loss:  0.2059324637055397\n",
      "Train Epoch: 45 [0/3276 (0%)]\tLoss: 0.385887\n",
      "Train Epoch: 45 [500/3276 (8%)]\tLoss: 0.422197\n",
      "Train Epoch: 45 [1000/3276 (15%)]\tLoss: 0.332490\n",
      "Train Epoch: 45 [1500/3276 (23%)]\tLoss: 0.446575\n",
      "Train Epoch: 45 [2000/3276 (30%)]\tLoss: 0.321147\n",
      "Train Epoch: 45 [2500/3276 (38%)]\tLoss: 0.322221\n",
      "\n",
      "Average Train Epoch Loss:  0.44925591304171375\n",
      "Average Train Bin Epoch Loss:  0.13330097594184848\n",
      "Average Train Count Epoch Loss:  0.0376487849564178\n",
      "Average Train Segmentation Epoch Loss:  0.14966023345364304\n",
      "Average Train X-Offset Epoch Loss:  0.08949604710427726\n",
      "Average Train Y-Offset Epoch Loss:  0.039149870319155664\n",
      "Average Validation Epoch Loss:  1.0290432125329971\n",
      "Average Validation Bin Epoch Loss:  0.2059778943657875\n",
      "Average Validation Count Epoch Loss:  0.06732066790573299\n",
      "Average Validation Segmentation Epoch Loss:  0.24955754727125168\n",
      "Average Validation X-Offset Epoch Loss:  0.2975368827581406\n",
      "Average Validation Y-Offset Epoch Loss:  0.20865021347999574\n",
      "Train Epoch: 46 [0/3276 (0%)]\tLoss: 0.425983\n",
      "Train Epoch: 46 [500/3276 (8%)]\tLoss: 0.424636\n",
      "Train Epoch: 46 [1000/3276 (15%)]\tLoss: 0.462532\n",
      "Train Epoch: 46 [1500/3276 (23%)]\tLoss: 0.517654\n",
      "Train Epoch: 46 [2000/3276 (30%)]\tLoss: 0.486446\n",
      "Train Epoch: 46 [2500/3276 (38%)]\tLoss: 0.555522\n",
      "Train Epoch: 46 [3000/3276 (46%)]\tLoss: 0.432885\n",
      "\n",
      "Average Train Epoch Loss:  0.447769538385839\n",
      "Average Train Bin Epoch Loss:  0.13303784726233017\n",
      "Average Train Count Epoch Loss:  0.03756089531816542\n",
      "Average Train Segmentation Epoch Loss:  0.1496775576435938\n",
      "Average Train X-Offset Epoch Loss:  0.08806247816580098\n",
      "Average Train Y-Offset Epoch Loss:  0.03943075739846724\n",
      "Average Validation Epoch Loss:  1.041866522282362\n",
      "Average Validation Bin Epoch Loss:  0.20738840755075216\n",
      "Average Validation Count Epoch Loss:  0.06942380941472948\n",
      "Average Validation Segmentation Epoch Loss:  0.2683082204312086\n",
      "Average Validation X-Offset Epoch Loss:  0.2957146435976029\n",
      "Average Validation Y-Offset Epoch Loss:  0.20103143379092217\n",
      "Train Epoch: 47 [0/3276 (0%)]\tLoss: 0.479309\n",
      "Train Epoch: 47 [500/3276 (8%)]\tLoss: 0.334704\n",
      "Train Epoch: 47 [1000/3276 (15%)]\tLoss: 0.499790\n",
      "Train Epoch: 47 [1500/3276 (23%)]\tLoss: 0.467737\n",
      "Train Epoch: 47 [2000/3276 (30%)]\tLoss: 0.355599\n",
      "Train Epoch: 47 [2500/3276 (38%)]\tLoss: 0.483909\n",
      "Train Epoch: 47 [3000/3276 (46%)]\tLoss: 0.467870\n",
      "\n",
      "Average Train Epoch Loss:  0.443161875282119\n",
      "Average Train Bin Epoch Loss:  0.13252871542623856\n",
      "Average Train Count Epoch Loss:  0.037039322733152205\n",
      "Average Train Segmentation Epoch Loss:  0.14840267487324593\n",
      "Average Train X-Offset Epoch Loss:  0.08654667308962928\n",
      "Average Train Y-Offset Epoch Loss:  0.03864448668844089\n",
      "Average Validation Epoch Loss:  1.027909766882658\n",
      "Average Validation Bin Epoch Loss:  0.20541092660278082\n",
      "Average Validation Count Epoch Loss:  0.06697289762087166\n",
      "Average Validation Segmentation Epoch Loss:  0.24424346629530191\n",
      "Average Validation X-Offset Epoch Loss:  0.30010417103767395\n",
      "Average Validation Y-Offset Epoch Loss:  0.21117830350995065\n",
      "Train Epoch: 48 [0/3276 (0%)]\tLoss: 0.481569\n",
      "Train Epoch: 48 [500/3276 (8%)]\tLoss: 0.471352\n",
      "Train Epoch: 48 [1000/3276 (15%)]\tLoss: 0.380144\n",
      "Train Epoch: 48 [1500/3276 (23%)]\tLoss: 0.481027\n",
      "Train Epoch: 48 [2000/3276 (30%)]\tLoss: 0.428097\n",
      "Train Epoch: 48 [2500/3276 (38%)]\tLoss: 0.519385\n",
      "Train Epoch: 48 [3000/3276 (46%)]\tLoss: 0.472288\n",
      "\n",
      "Average Train Epoch Loss:  0.4402328546999431\n",
      "Average Train Bin Epoch Loss:  0.13182849409740147\n",
      "Average Train Count Epoch Loss:  0.036902295788977205\n",
      "Average Train Segmentation Epoch Loss:  0.14676393868356216\n",
      "Average Train X-Offset Epoch Loss:  0.08603660113564351\n",
      "Average Train Y-Offset Epoch Loss:  0.03870152234122521\n",
      "Average Validation Epoch Loss:  1.0089941695332527\n",
      "Average Validation Bin Epoch Loss:  0.20434967707842588\n",
      "Average Validation Count Epoch Loss:  0.06553651578724384\n",
      "Average Validation Segmentation Epoch Loss:  0.23953476920723915\n",
      "Average Validation X-Offset Epoch Loss:  0.2952377200126648\n",
      "Average Validation Y-Offset Epoch Loss:  0.2043354719877243\n",
      "Train Epoch: 49 [0/3276 (0%)]\tLoss: 0.525465\n",
      "Train Epoch: 49 [500/3276 (8%)]\tLoss: 0.514142\n",
      "Train Epoch: 49 [1000/3276 (15%)]\tLoss: 0.478548\n",
      "Train Epoch: 49 [1500/3276 (23%)]\tLoss: 0.488461\n",
      "Train Epoch: 49 [2000/3276 (30%)]\tLoss: 0.410699\n",
      "Train Epoch: 49 [2500/3276 (38%)]\tLoss: 0.484650\n",
      "Train Epoch: 49 [3000/3276 (46%)]\tLoss: 0.426662\n",
      "\n",
      "Average Train Epoch Loss:  0.4389824428391166\n",
      "Average Train Bin Epoch Loss:  0.13202313311034586\n",
      "Average Train Count Epoch Loss:  0.03649566876815587\n",
      "Average Train Segmentation Epoch Loss:  0.14767868873640533\n",
      "Average Train X-Offset Epoch Loss:  0.08478389714912671\n",
      "Average Train Y-Offset Epoch Loss:  0.03800105370308568\n",
      "Average Validation Epoch Loss:  1.035658098757267\n",
      "Average Validation Bin Epoch Loss:  0.2037519821897149\n",
      "Average Validation Count Epoch Loss:  0.06642923248000443\n",
      "Average Validation Segmentation Epoch Loss:  0.2466479241847992\n",
      "Average Validation X-Offset Epoch Loss:  0.3016266360878944\n",
      "Average Validation Y-Offset Epoch Loss:  0.21720231249928476\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 50 [0/3276 (0%)]\tLoss: 0.404966\n",
      "Train Epoch: 50 [500/3276 (8%)]\tLoss: 0.458979\n",
      "Train Epoch: 50 [1000/3276 (15%)]\tLoss: 0.453123\n",
      "Train Epoch: 50 [1500/3276 (23%)]\tLoss: 0.447854\n",
      "Train Epoch: 50 [2000/3276 (30%)]\tLoss: 0.453708\n",
      "Train Epoch: 50 [2500/3276 (38%)]\tLoss: 0.399273\n",
      "Train Epoch: 50 [3000/3276 (46%)]\tLoss: 0.416211\n",
      "\n",
      "Average Train Epoch Loss:  0.43852776943183525\n",
      "Average Train Bin Epoch Loss:  0.1314563690344008\n",
      "Average Train Count Epoch Loss:  0.03650854839716197\n",
      "Average Train Segmentation Epoch Loss:  0.1473191399127245\n",
      "Average Train X-Offset Epoch Loss:  0.08438822916004715\n",
      "Average Train Y-Offset Epoch Loss:  0.038855479793941106\n",
      "Average Validation Epoch Loss:  1.0159697718918324\n",
      "Average Validation Bin Epoch Loss:  0.2044970067217946\n",
      "Average Validation Count Epoch Loss:  0.06490784836933017\n",
      "Average Validation Segmentation Epoch Loss:  0.23988137301057577\n",
      "Average Validation X-Offset Epoch Loss:  0.29544949233531953\n",
      "Average Validation Y-Offset Epoch Loss:  0.21123403385281564\n",
      "Train Epoch: 51 [0/3276 (0%)]\tLoss: 0.364983\n",
      "Train Epoch: 51 [500/3276 (8%)]\tLoss: 0.354184\n",
      "Train Epoch: 51 [1000/3276 (15%)]\tLoss: 0.414331\n",
      "Train Epoch: 51 [1500/3276 (23%)]\tLoss: 0.485798\n",
      "Train Epoch: 51 [2000/3276 (30%)]\tLoss: 0.446675\n",
      "Train Epoch: 51 [2500/3276 (38%)]\tLoss: 0.579284\n",
      "Train Epoch: 51 [3000/3276 (46%)]\tLoss: 0.558468\n",
      "\n",
      "Average Train Epoch Loss:  0.4325011123607798\n",
      "Average Train Bin Epoch Loss:  0.1302890653108678\n",
      "Average Train Count Epoch Loss:  0.036163512055148804\n",
      "Average Train Segmentation Epoch Loss:  0.1452508054946254\n",
      "Average Train X-Offset Epoch Loss:  0.08350103275804985\n",
      "Average Train Y-Offset Epoch Loss:  0.03729669358127001\n",
      "Average Validation Epoch Loss:  1.0078468658030033\n",
      "Average Validation Bin Epoch Loss:  0.21054916456341743\n",
      "Average Validation Count Epoch Loss:  0.06395690562203526\n",
      "Average Validation Segmentation Epoch Loss:  0.24254276044666767\n",
      "Average Validation X-Offset Epoch Loss:  0.28483290746808054\n",
      "Average Validation Y-Offset Epoch Loss:  0.20596512258052826\n",
      "Train Epoch: 52 [0/3276 (0%)]\tLoss: 0.438244\n",
      "Train Epoch: 52 [500/3276 (8%)]\tLoss: 0.378968\n",
      "Train Epoch: 52 [1000/3276 (15%)]\tLoss: 0.343321\n",
      "Train Epoch: 52 [1500/3276 (23%)]\tLoss: 0.482277\n",
      "Train Epoch: 52 [2000/3276 (30%)]\tLoss: 0.423465\n",
      "Train Epoch: 52 [2500/3276 (38%)]\tLoss: 0.451887\n",
      "Train Epoch: 52 [3000/3276 (46%)]\tLoss: 0.436623\n",
      "\n",
      "Average Train Epoch Loss:  0.43131211981540774\n",
      "Average Train Bin Epoch Loss:  0.1304333834204732\n",
      "Average Train Count Epoch Loss:  0.03627419957845676\n",
      "Average Train Segmentation Epoch Loss:  0.14394351510649048\n",
      "Average Train X-Offset Epoch Loss:  0.08296320972646155\n",
      "Average Train Y-Offset Epoch Loss:  0.037697808985121366\n",
      "Average Validation Epoch Loss:  1.0290455929934978\n",
      "Average Validation Bin Epoch Loss:  0.2056112177670002\n",
      "Average Validation Count Epoch Loss:  0.06743356632068753\n",
      "Average Validation Segmentation Epoch Loss:  0.2506002327427268\n",
      "Average Validation X-Offset Epoch Loss:  0.30085324794054036\n",
      "Average Validation Y-Offset Epoch Loss:  0.20454731136560442\n",
      "Train Epoch: 53 [0/3276 (0%)]\tLoss: 0.281220\n",
      "Train Epoch: 53 [500/3276 (8%)]\tLoss: 0.323905\n",
      "Train Epoch: 53 [1000/3276 (15%)]\tLoss: 0.452933\n",
      "Train Epoch: 53 [1500/3276 (23%)]\tLoss: 0.525084\n",
      "Train Epoch: 53 [2500/3276 (38%)]\tLoss: 0.483278\n",
      "Train Epoch: 53 [3000/3276 (46%)]\tLoss: 0.507560\n",
      "\n",
      "Average Train Epoch Loss:  0.4282364647199468\n",
      "Average Train Bin Epoch Loss:  0.1297238511146932\n",
      "Average Train Count Epoch Loss:  0.03570544943440615\n",
      "Average Train Segmentation Epoch Loss:  0.14445019205577853\n",
      "Average Train X-Offset Epoch Loss:  0.08198643158666973\n",
      "Average Train Y-Offset Epoch Loss:  0.03637053978788417\n",
      "Average Validation Epoch Loss:  1.0199458189308643\n",
      "Average Validation Bin Epoch Loss:  0.20429209526628256\n",
      "Average Validation Count Epoch Loss:  0.0654318006709218\n",
      "Average Validation Segmentation Epoch Loss:  0.2491949489340186\n",
      "Average Validation X-Offset Epoch Loss:  0.2973213449120522\n",
      "Average Validation Y-Offset Epoch Loss:  0.2037056222558022\n",
      "Train Epoch: 54 [0/3276 (0%)]\tLoss: 0.390794\n",
      "Train Epoch: 54 [500/3276 (8%)]\tLoss: 0.417355\n",
      "Train Epoch: 54 [1000/3276 (15%)]\tLoss: 0.454192\n",
      "Train Epoch: 54 [1500/3276 (23%)]\tLoss: 0.543832\n",
      "Train Epoch: 54 [2000/3276 (30%)]\tLoss: 0.566459\n",
      "Train Epoch: 54 [2500/3276 (38%)]\tLoss: 0.399856\n",
      "Train Epoch: 54 [3000/3276 (46%)]\tLoss: 0.323148\n",
      "\n",
      "Average Train Epoch Loss:  0.42688535099349373\n",
      "Average Train Bin Epoch Loss:  0.12924604942431536\n",
      "Average Train Count Epoch Loss:  0.035208130755075596\n",
      "Average Train Segmentation Epoch Loss:  0.14353684902690897\n",
      "Average Train X-Offset Epoch Loss:  0.08205096371835327\n",
      "Average Train Y-Offset Epoch Loss:  0.03684335611306313\n",
      "Average Validation Epoch Loss:  1.0120801478624344\n",
      "Average Validation Bin Epoch Loss:  0.20633035339415073\n",
      "Average Validation Count Epoch Loss:  0.06550077442079782\n",
      "Average Validation Segmentation Epoch Loss:  0.23985741008073092\n",
      "Average Validation X-Offset Epoch Loss:  0.29467973560094834\n",
      "Average Validation Y-Offset Epoch Loss:  0.20571186617016793\n",
      "Train Epoch: 55 [0/3276 (0%)]\tLoss: 0.401755\n",
      "Train Epoch: 55 [500/3276 (8%)]\tLoss: 0.400199\n",
      "Train Epoch: 55 [1000/3276 (15%)]\tLoss: 0.481083\n",
      "Train Epoch: 55 [1500/3276 (23%)]\tLoss: 0.288129\n",
      "Train Epoch: 55 [2000/3276 (30%)]\tLoss: 0.380911\n",
      "Train Epoch: 55 [2500/3276 (38%)]\tLoss: 0.458078\n",
      "Train Epoch: 55 [3000/3276 (46%)]\tLoss: 0.361887\n",
      "\n",
      "Average Train Epoch Loss:  0.4258549201597528\n",
      "Average Train Bin Epoch Loss:  0.12916973017428707\n",
      "Average Train Count Epoch Loss:  0.03518756018474516\n",
      "Average Train Segmentation Epoch Loss:  0.14393051072001095\n",
      "Average Train X-Offset Epoch Loss:  0.08101854696869851\n",
      "Average Train Y-Offset Epoch Loss:  0.03654857074796427\n",
      "Average Validation Epoch Loss:  1.0020278505980968\n",
      "Average Validation Bin Epoch Loss:  0.204369836486876\n",
      "Average Validation Count Epoch Loss:  0.06375494599342346\n",
      "Average Validation Segmentation Epoch Loss:  0.23742018826305866\n",
      "Average Validation X-Offset Epoch Loss:  0.2921195521950722\n",
      "Average Validation Y-Offset Epoch Loss:  0.20436331033706664\n",
      "Train Epoch: 56 [0/3276 (0%)]\tLoss: 0.406253\n",
      "Train Epoch: 56 [500/3276 (8%)]\tLoss: 0.369845\n",
      "Train Epoch: 56 [1000/3276 (15%)]\tLoss: 0.517006\n",
      "Train Epoch: 56 [1500/3276 (23%)]\tLoss: 0.483031\n",
      "Train Epoch: 56 [2000/3276 (30%)]\tLoss: 0.394459\n",
      "Train Epoch: 56 [2500/3276 (38%)]\tLoss: 0.417882\n",
      "Train Epoch: 56 [3000/3276 (46%)]\tLoss: 0.464223\n",
      "\n",
      "Average Train Epoch Loss:  0.42081739917034056\n",
      "Average Train Bin Epoch Loss:  0.12848560095242248\n",
      "Average Train Count Epoch Loss:  0.035177345285419284\n",
      "Average Train Segmentation Epoch Loss:  0.1422538027258181\n",
      "Average Train X-Offset Epoch Loss:  0.07869889606244682\n",
      "Average Train Y-Offset Epoch Loss:  0.036201753281056875\n",
      "Average Validation Epoch Loss:  1.0066308081150055\n",
      "Average Validation Bin Epoch Loss:  0.20371942408382893\n",
      "Average Validation Count Epoch Loss:  0.06630143732763827\n",
      "Average Validation Segmentation Epoch Loss:  0.23455654736608267\n",
      "Average Validation X-Offset Epoch Loss:  0.2958848476409912\n",
      "Average Validation Y-Offset Epoch Loss:  0.20616853311657907\n",
      "Train Epoch: 57 [0/3276 (0%)]\tLoss: 0.411874\n",
      "Train Epoch: 57 [500/3276 (8%)]\tLoss: 0.435584\n",
      "Train Epoch: 57 [1000/3276 (15%)]\tLoss: 0.445218\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    train()\n",
    "    val()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 60 x 200\n",
    "# 10 x 1200\n",
    "x = torch.randn((12, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute threat scores\n",
    "def reconstruct_from_bins(bins, block_size, threshold):\n",
    "    print(bins.shape)\n",
    "    road_map = torch.zeros((800, 800))\n",
    "    idx = 0\n",
    "    for x in range(0, 800, block_size):\n",
    "        for y in range(0, 800, block_size):\n",
    "            road_map[x:x+block_size, y:y+block_size] = bins[idx]\n",
    "            idx += 1\n",
    "    return road_map > threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SimpleModel().to(device)\n",
    "model.load_state_dict(torch.load('/scratch/brs426/all_six_images_classify_count_better.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Threat Score Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "torch.Size([25600])\n",
      "Average threat score tensor(0.8504)\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "threat_scores = 0\n",
    "threshold = 0.4\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (sample, target, road_img, bbs, target_count, road_bins) in enumerate(val_loader):\n",
    "        sample = sample.to(device)\n",
    "        target = target.to(device)\n",
    "        road_bins = road_bins.to(device)\n",
    "        target_count = target_count.to(device)\n",
    "        \n",
    "        y_hat, y_count, segmentation = model(sample)\n",
    "        segmentation = segmentation.squeeze()\n",
    "        road_img = road_img.squeeze()\n",
    "        \n",
    "        reconstructed_road_map = reconstruct_from_bins(segmentation, 5, threshold).cpu()\n",
    "        ts_road_map = compute_ts_road_map(road_img,reconstructed_road_map)\n",
    "        threat_scores += ts_road_map\n",
    "    \n",
    "    print(\"Average threat score\", threat_scores / len(val_loader))\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    BLOCK_SIZE = 5\n",
    "    images = []\n",
    "    target = []\n",
    "    road_maps = []\n",
    "    road_bins = []\n",
    "    bbs = []\n",
    "    target_counts = []\n",
    "    for x in batch:\n",
    "        \n",
    "        grid = []\n",
    "        # Get road_image and cast it to float\n",
    "        road_image = torch.as_tensor(x[2])\n",
    "        road_maps.append(road_image)\n",
    "        road_image = road_image.float()\n",
    "        \n",
    "        # Split up into blocks and assign pixel value for block\n",
    "        for x_ in range(0, 800, BLOCK_SIZE):\n",
    "            for y in range(0, 800, BLOCK_SIZE):\n",
    "                block = road_image[x_:x_+BLOCK_SIZE, y:y+BLOCK_SIZE]\n",
    "                score = torch.sum(block).item()\n",
    "                # If more than have the pixels are 1, classify as road\n",
    "                if score > (BLOCK_SIZE**2) / 2:\n",
    "                    grid.append(1.0)\n",
    "                else:\n",
    "                    grid.append(0.0)\n",
    "                \n",
    "        road_bins.append(torch.Tensor(grid))\n",
    "        \n",
    "        # Collect six images for this sample. \n",
    "        six_images = []\n",
    "        for i in range(6):\n",
    "            six_images.append(torch.Tensor(x[0][i]))\n",
    "        \n",
    "        \n",
    "        # target\n",
    "        bb_tens = x[1]['bounding_box']\n",
    "        current_bbs = []\n",
    "        bins = np.zeros(256)\n",
    "        counts = np.zeros(90)\n",
    "        count = 0\n",
    "        \n",
    "        for i, corners in enumerate(bb_tens):\n",
    "#             if x[1]['category'][i] not in [1, 3, 6, 8]:\n",
    "            # Grab the current bounding box. \n",
    "            current_bbs.append(corners)\n",
    "\n",
    "            # Get its four bird's-eye view coordinates.\n",
    "            point_squence = torch.stack([corners[:, 0], corners[:, 1], corners[:, 3], corners[:, 2]])\n",
    "            xs = point_squence.T[0] * 10 + 400\n",
    "            ys = -point_squence.T[1] * 10 + 400\n",
    "\n",
    "            # Find the bin/grid cell it falls in, get its class mapping. \n",
    "            center_x, center_y = torch.mean(xs).item(), torch.mean(ys).item()\n",
    "            key = (round_down(center_x), round_down(center_y))\n",
    "            if key not in class_dict:\n",
    "                print(key)\n",
    "            bin_id = class_dict[key]\n",
    "            bins[bin_id] = 1\n",
    "            count += 1\n",
    "            \n",
    "        \n",
    "        counts[count] = 1\n",
    "\n",
    "        # Label Smoothing #\n",
    "        if count > 10 and count < 88:\n",
    "            counts[count+1] = 0.2\n",
    "            counts[count-1] = 0.2\n",
    "        target_counts.append(torch.Tensor(counts))\n",
    "        \n",
    "        images.append(torch.stack(six_images))\n",
    "                \n",
    "        target.append(torch.Tensor(bins))\n",
    "        \n",
    "        bbs.append(current_bbs)\n",
    "                \n",
    "    boom = torch.stack(images), torch.stack(target), torch.stack(road_maps), bbs, torch.stack(target_counts), torch.stack(road_bins)\n",
    "    return boom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transform = transforms.ToTensor()\n",
    "labeled_testset = LabeledDataset(image_folder=image_folder,\n",
    "                                  annotation_file=annotation_csv,\n",
    "                                  scene_index=test_labeled_scene_index,\n",
    "                                  transform=test_transform,\n",
    "                                  extra_info=True\n",
    "                                 )\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(labeled_testset, batch_size=1, shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average threat score tensor(0.0066)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class_label = 0\n",
    "class_dict = dict()\n",
    "reverse_class_dict = []\n",
    "for i in range(0, 800, 50):\n",
    "    for j in range(0, 800, 50):\n",
    "        class_dict[(i, j)] = class_label\n",
    "        class_label += 1\n",
    "        reverse_class_dict.append((i, j))\n",
    "\n",
    "\n",
    "model.eval()\n",
    "\n",
    "threat_scores = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (sample, target, road_img, bbs, target_count, road_bins) in enumerate(test_loader):\n",
    "        bb_samples = []\n",
    "        sample = sample.to(device)\n",
    "        target = target.to(device)\n",
    "        road_bins = road_bins.to(device)\n",
    "        target_count = target_count.to(device)\n",
    "        \n",
    "        y_hat, y_count, segmentation = model(sample)\n",
    "        \n",
    "        if torch.argmax(y_count).item() > 15:\n",
    "            result = torch.topk(y_hat, k = 6 + torch.argmax(y_count).item())\n",
    "            pred_ids = result.indices\n",
    "        else:\n",
    "            result = torch.topk(y_hat, k = torch.argmax(y_count).item())\n",
    "            pred_ids = result.indices\n",
    "\n",
    "        bounding_boxes = []\n",
    "        for idx in pred_ids[0]:\n",
    "            bin_x, bin_y = reverse_class_dict[idx.item()]\n",
    "\n",
    "            xs = torch.Tensor([bin_x, bin_x, bin_x + 50, bin_x + 50]).double()\n",
    "            ys = torch.Tensor([bin_y+16, bin_y+36, bin_y+16, bin_y+36]).double()\n",
    "\n",
    "            xs = xs - 400\n",
    "            ys = 800 - ys # right-side up\n",
    "            ys = ys - 400\n",
    "\n",
    "            xs /= 10.\n",
    "            ys /= 10.\n",
    "\n",
    "            coords = torch.stack((xs, ys))\n",
    "            bounding_boxes.append(coords)\n",
    "\n",
    "        bounding_boxes = torch.stack(bounding_boxes).double().cuda()\n",
    "        bb_samples.append(bounding_boxes)\n",
    "        bb_samples = tuple(bb_samples)\n",
    "                \n",
    "        bb_samples = bb_samples[0].cpu()\n",
    "        bbs = torch.stack(bbs[0]).cpu()\n",
    "        ts_bounding_box = compute_ats_bounding_boxes(bb_samples, bbs)\n",
    "        \n",
    "        threat_scores += ts_bounding_box\n",
    "    \n",
    "    print(\"Average threat score\", threat_scores / len(test_loader))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.253 val bin loss\n",
    "\n",
    "# Random Affine 3 degrees\n",
    "# 0.263 val bin loss\n",
    "\n",
    "\n",
    "# Need to do 5 * bin_loss + count_loss or something like that. Also more extreme Random Affine maybe?\n",
    "\n",
    "# Random Affine 5 degrees\n",
    "# 0.266 val bin loss\n",
    "\n",
    "# Took out Random Affine. \n",
    "# 0.268 val bin loss\n",
    "\n",
    "# Increased compress dim from 128 to 200. \n",
    "# 0.259 val bin loss\n",
    "\n",
    "# 5 * bin_loss + count_loss\n",
    "# 0.249 + 0.055\n",
    "\n",
    "# 8 *\n",
    "# 0.251 + 0.054\n",
    "\n",
    "# 8*, RandomAffine(3)\n",
    "# 0.255\n",
    "\n",
    "# 8*, RandomAffine(3), weight_decay 0.1\n",
    "\n",
    "# 10 *, RandomAffine(3)\n",
    "# 0.259\n",
    "\n",
    "# 8 *, Normalize (mean, std)\n",
    "# 0.26\n",
    "\n",
    "# 8 *, Dropout\n",
    "# 0.241, 0.253\n",
    "\n",
    "# 5 *, Dropout\n",
    "# 0.254\n",
    "\n",
    "# 11 *, Dropout\n",
    "# 0.249\n",
    "\n",
    "# Want to try positive-weights for classes within 200 to 600. \n",
    "# Want to get the model to get those classes correct. \n",
    "\n",
    "# Mixup 0.2, 1 *, Dropout\n",
    "# (0.244, 0.053), \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Model Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        \n",
    "        self.encoder = torchvision.models.resnet50()\n",
    "        self.encoder.fc = nn.Identity()\n",
    "        self.concat_dim = 200 * 6\n",
    "        \n",
    "        self.compress = nn.Sequential(OrderedDict([\n",
    "            ('linear0', nn.Linear(2048, 200)),\n",
    "            ('drop', nn.Dropout(p = 0.5)),\n",
    "            ('relu', nn.ReLU()),\n",
    "        ]))\n",
    "        \n",
    "        self.classification = nn.Sequential(OrderedDict([\n",
    "            ('linear1', nn.Linear(self.concat_dim, 256)),\n",
    "        ]))\n",
    "        \n",
    "        self.counts = nn.Sequential(OrderedDict([\n",
    "            ('count1', nn.Linear(self.concat_dim, 90))\n",
    "        ]))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.compress(x)\n",
    "        x = x.view(-1, self.concat_dim)\n",
    "        return self.classification(x), self.counts(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleModel()\n",
    "model.load_state_dict(torch.load('all_six_images_classify_count.pt'))\n",
    "model.cuda()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_label = 0\n",
    "class_dict = dict()\n",
    "reverse_class_dict = []\n",
    "for i in range(0, 800, 50):\n",
    "    for j in range(0, 800, 50):\n",
    "        class_dict[(i, j)] = class_label\n",
    "        class_label += 1\n",
    "        reverse_class_dict.append((i, j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bounding_boxes(samples):\n",
    "    \n",
    "    # samples is (batch_size, 6, 3, 256, 306)\n",
    "    \n",
    "    # You need to return a tuple with size batch_size and each element is a cuda tensor [N, 2, 4]\n",
    "    # where N is the number of bounding boxes. \n",
    "    \n",
    "    # Okay so I have my model. \n",
    "    # \n",
    "    \n",
    "    bb_samples = []\n",
    "    \n",
    "    for x in samples:\n",
    "        preds_class, preds_count = model(x)\n",
    "        \n",
    "        # preds class is a 256-dimensional tensor, filled with probabilities\n",
    "        # I need to find the `preds_count` top indices with the top values.\n",
    "        \n",
    "        \n",
    "        result = torch.topk(preds_class, k = torch.argmax(preds_count).item())\n",
    "        pred_ids = result.indices\n",
    "        \n",
    "        bounding_boxes = []\n",
    "        for idx in pred_ids[0]:\n",
    "            buck_x, buck_y = reverse_class_dict[idx.item()]\n",
    "            \n",
    "            xs = torch.as_tensor([buck_x, buck_x, buck_x + 50, buck_x + 50])\n",
    "            ys = torch.as_tensor([buck_y+16, buck_y+36, buck_y+16, buck_y+36])\n",
    "            \n",
    "            xs = xs - 400\n",
    "            ys = 800 - ys # right-side up\n",
    "            ys = ys - 400\n",
    "            \n",
    "            xs /= 10\n",
    "            ys /= 10\n",
    "               \n",
    "            coords = torch.stack((xs, ys))\n",
    "            bounding_boxes.append(coords)\n",
    "            \n",
    "        bounding_boxes = torch.stack(bounding_boxes).cuda()\n",
    "        bb_samples.append(bounding_boxes)\n",
    "    \n",
    "    return tuple(bb_samples)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample, target, road_img, bbs, counts = iter(val_loader).next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = sample.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boom = get_bounding_boxes(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoid_preds = torch.sigmoid(model(sample[idx])[0]).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(torchvision.utils.make_grid(sample[idx].cpu().detach(), nrow=3).numpy().transpose(1, 2, 0))\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.imshow(road_img[idx], cmap ='binary');\n",
    "ax.plot(400, 400, 'x', color=\"red\")\n",
    "\n",
    "# `target` is 32 by 81. Find the indices where there's a 1. \n",
    "\n",
    "bin_ids = (sigmoid_preds > 0.25).nonzero()\n",
    "for bin_id in bin_ids:\n",
    "    class_box = reverse_class_dict[bin_id]\n",
    "    draw_vish_box(ax, class_box, 'red')\n",
    "    \n",
    "bin_ids = (target[idx] == 1).nonzero()\n",
    "for bin_id in bin_ids:\n",
    "    class_box = reverse_class_dict[bin_id]\n",
    "    draw_vish_box(ax, class_box, 'green')\n",
    "\n",
    "    \n",
    "for bb in boom[idx]:\n",
    "    box = bb.cpu().detach()\n",
    "    draw_box(ax, box, 'orange')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.stack([box[:, 0], box[:, 1], box[:, 3], box[:, 2], box[:, 0]])\n",
    "\n",
    "def draw_box(ax, corners, color):\n",
    "    point_squence = torch.stack([corners[:, 0], corners[:, 1], corners[:, 3], corners[:, 2], corners[:, 0]])\n",
    "    \n",
    "    # the corners are in meter and time 10 will convert them in pixels\n",
    "    # Add 400, since the center of the image is at pixel (400, 400)\n",
    "    # The negative sign is because the y axis is reversed for matplotlib\n",
    "    ax.plot(point_squence.T[0] * 10 + 400, -point_squence.T[1] * 10 + 400, color=color)\n",
    "    return point_squence.T[0] * 10 + 400, -point_squence.T[1] * 10 + 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_vish_box(ax, class_box, color):\n",
    "    box_xs = [class_box[0], class_box[0], class_box[0]+50, class_box[0]+50, class_box[0]]\n",
    "    box_ys = [class_box[1], class_box[1]+50, class_box[1]+50, class_box[1], class_box[1]]\n",
    "    ax.plot(box_xs, box_ys, color=color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
