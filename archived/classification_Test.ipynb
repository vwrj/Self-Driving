{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pdb\n",
    "from collections import OrderedDict\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import collections  as mc\n",
    "matplotlib.rcParams['figure.figsize'] = [5, 5]\n",
    "matplotlib.rcParams['figure.dpi'] = 200\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "from data_helper import UnlabeledDataset, LabeledDataset\n",
    "from helper import collate_fn, draw_box\n",
    "\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0);\n",
    "\n",
    "# All the images are saved in image_folder\n",
    "# All the labels are saved in the annotation_csv file\n",
    "image_folder = '/scratch/vr1059/self-driving-data/data'\n",
    "annotation_csv = '/scratch/vr1059/self-driving-data/data/annotation.csv'\n",
    "\n",
    "# You shouldn't change the unlabeled_scene_index\n",
    "# The first 106 scenes are unlabeled\n",
    "unlabeled_scene_index = np.arange(106)\n",
    "# The scenes from 106 - 133 are labeled\n",
    "# You should devide the labeled_scene_index into two subsets (training and validation)\n",
    "train_labeled_scene_index = np.arange(106, 128)\n",
    "val_labeled_scene_index = np.arange(128, 132)\n",
    "test_labeled_scene_index = np.arange(132, 134)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unit_vector(vector):\n",
    "    \"\"\" Returns the unit vector of the vector.  \"\"\"\n",
    "    return vector / np.linalg.norm(vector)\n",
    "\n",
    "def angle_between(v1, v2):\n",
    "    \"\"\" Returns the angle in radians between vectors 'v1' and 'v2'::\n",
    "\n",
    "            >>> angle_between((1, 0, 0), (0, 1, 0))\n",
    "            1.5707963267948966\n",
    "            >>> angle_between((1, 0, 0), (1, 0, 0))\n",
    "            0.0\n",
    "            >>> angle_between((1, 0, 0), (-1, 0, 0))\n",
    "            3.141592653589793\n",
    "    \"\"\"\n",
    "    v1_u = unit_vector(v1)\n",
    "    v2_u = unit_vector(v2)\n",
    "    return np.degrees(np.arccos(np.clip(np.dot(v1_u, v2_u), -1.0, 1.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_label = 1\n",
    "class_dict = dict()\n",
    "reverse_class_dict = []\n",
    "reverse_class_dict.append((-100, -100))\n",
    "for i in range(400, 800, 50):\n",
    "    for j in range(100, 600, 50):\n",
    "        class_dict[(i, j)] = class_label\n",
    "        class_label += 1\n",
    "        reverse_class_dict.append((i, j))\n",
    "        \n",
    "class_dict[(-100, -100)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_up(x):\n",
    "    return int(math.ceil(x / 50.0)) * 50\n",
    "\n",
    "def round_down(x):\n",
    "    return round_up(x) - 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def front_collate_fn(batch):\n",
    "    front_imgs = []\n",
    "    front_right_imgs = []\n",
    "    front_left_imgs = []\n",
    "    target = []\n",
    "    road_imgs = []\n",
    "    bbs = []\n",
    "    for x in batch:\n",
    "        # input\n",
    "        front_left_imgs.append(torch.tensor(x[0][0]))\n",
    "        front_imgs.append(torch.tensor(x[0][1]))\n",
    "        front_right_imgs.append(torch.tensor(x[0][2]))\n",
    "        road_imgs.append(torch.tensor(x[2]))\n",
    "        \n",
    "        # target\n",
    "        bb_tens = x[1]['bounding_box']\n",
    "        bbs.append(bb_tens)\n",
    "        x_min = 800\n",
    "        bb_cand = (-100., -100.)\n",
    "        \n",
    "        for i, corners in enumerate(bb_tens):\n",
    "            # Get bird's eye view coordinates. \n",
    "            point_squence = torch.stack([corners[:, 0], corners[:, 1], corners[:, 3], corners[:, 2]])\n",
    "            xs = point_squence.T[0] * 10 + 400\n",
    "            ys = -point_squence.T[1] * 10 + 400\n",
    "            if xs[2] - xs[0] > 5:\n",
    "                top_center_x, top_center_y = 0.5*(xs[2] + xs[3]), 0.5*(ys[2] + ys[3])\n",
    "            else:\n",
    "                top_center_x, top_center_y = 0.5*(xs[0] + xs[1]), 0.5*(ys[0] + ys[1])\n",
    "                \n",
    "            # We do (800 - top_center_y) because matplotlib y-axis starts from the top. \n",
    "            v1 = np.array([top_center_x - 400, 800 - top_center_y - 400])\n",
    "            v2 = np.array([2, 0])\n",
    "            \n",
    "            if abs(angle_between(v1, v2)) <= 35 and x[1]['category'][i] not in [1, 3, 6, 8]:\n",
    "                if top_center_x < x_min:\n",
    "                    x_min = top_center_x\n",
    "                    bb_cand = (top_center_x.item(), top_center_y.item())\n",
    "         \n",
    "        if int(bb_cand[0]) == -100:\n",
    "            target.append((0, bb_cand[0]/100., bb_cand[1]/100.))\n",
    "        else:\n",
    "            key = (round_down(bb_cand[0]), round_down(bb_cand[1]))\n",
    "            if key not in class_dict:\n",
    "                print(bb_cand)\n",
    "            label = class_dict[key]\n",
    "            target.append((label, bb_cand[0]/100., bb_cand[1]/100.))\n",
    "                \n",
    "    boom = torch.stack(front_imgs), torch.tensor(target), torch.stack(road_imgs), bbs, torch.stack(front_right_imgs), torch.stack(front_left_imgs)\n",
    "    return boom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The labeled dataset can only be retrieved by sample.\n",
    "# And all the returned data are tuple of tensors, since bounding boxes may have different size\n",
    "# You can choose whether the loader returns the extra_info. It is optional. You don't have to use it.\n",
    "val_transform = transforms.ToTensor()\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomApply([\n",
    "        transforms.ColorJitter(brightness = 0.5, contrast = 0.3, saturation = 0.2, hue = (-0.3, 0.3)),\n",
    "        transforms.Grayscale(3),\n",
    "        transforms.RandomAffine(5),\n",
    "    ]),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "labeled_trainset = LabeledDataset(image_folder=image_folder,\n",
    "                                  annotation_file=annotation_csv,\n",
    "                                  scene_index=train_labeled_scene_index,\n",
    "                                  transform=train_transform,\n",
    "                                  extra_info=True\n",
    "                                 )\n",
    "labeled_valset = LabeledDataset(image_folder=image_folder,\n",
    "                                  annotation_file=annotation_csv,\n",
    "                                  scene_index=val_labeled_scene_index,\n",
    "                                  transform=val_transform,\n",
    "                                  extra_info=True\n",
    "                                 )\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(labeled_trainset, batch_size=256, shuffle=True, collate_fn=front_collate_fn)\n",
    "val_loader = torch.utils.data.DataLoader(labeled_valset, batch_size=256, shuffle=False, collate_fn=front_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        \n",
    "        self.encoder = torchvision.models.resnet18()\n",
    "        self.encoder.fc = nn.Identity()\n",
    "        \n",
    "        self.classification = nn.Sequential(OrderedDict([\n",
    "            ('linear1', nn.Linear(512, 81)),\n",
    "        ]))\n",
    "        \n",
    "        self.regression = nn.Sequential(OrderedDict([\n",
    "            ('linear_reg', nn.Linear(512, 2)),\n",
    "        ]))\n",
    "        \n",
    "#         self.regression.linear1.bias = nn.Parameter(torch.tensor(400.))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        return self.classification(x), self.regression(x)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleModel().to(device)\n",
    "class_criterion = nn.CrossEntropyLoss()\n",
    "reg_criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "best_val_loss = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    train_losses = []\n",
    "    class_losses = []\n",
    "    reg_losses = []\n",
    "    for i, (sample, target, road_img, bbs, front_right, front_left) in enumerate(train_loader):\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        sample = sample.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        y_hat_class, y_hat_reg = model(sample)\n",
    "        target_class = target[:, 0]\n",
    "        target_reg = target[:, 1:]\n",
    "        \n",
    "        class_loss = class_criterion(y_hat_class, target_class.long())\n",
    "        reg_loss = reg_criterion(y_hat_reg, target_reg)\n",
    "        loss = class_loss + 0.5 * reg_loss\n",
    "        \n",
    "        train_losses.append(loss.item())\n",
    "        class_losses.append(class_loss.item())\n",
    "        reg_losses.append(reg_loss.item())\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, i * len(sample), len(train_loader.dataset),\n",
    "                10. * i / len(train_loader), loss.item()))\n",
    "            print('Classify Loss: {}'.format(np.mean(class_losses)))\n",
    "            print('Regression Loss: {}'.format(np.mean(reg_losses)))\n",
    "            \n",
    "    print(\"\\nAverage Train Epoch Loss: \", np.mean(train_losses))\n",
    "            \n",
    "def val():\n",
    "    model.eval()\n",
    "    val_losses = []\n",
    "    class_losses = []\n",
    "    reg_losses = []\n",
    "    for i, (sample, target, road_img, bbs, front_right, front_left) in enumerate(val_loader):\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        sample = sample.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            y_hat_class, y_hat_reg = model(sample)\n",
    "            target_class = target[:, 0]\n",
    "            target_reg = target[:, 1:]\n",
    "\n",
    "            class_loss = class_criterion(y_hat_class, target_class.long())\n",
    "            reg_loss = reg_criterion(y_hat_reg, target_reg)\n",
    "            loss = class_loss + 0.5 * reg_loss\n",
    "\n",
    "            val_losses.append(loss.item())\n",
    "            class_losses.append(class_loss.item())\n",
    "            reg_losses.append(reg_loss.item())\n",
    "\n",
    "#         if i % 5 == 0:\n",
    "#             print('Val Epoch: {} [{}/{} ({:.0f}%)]\\tAverage Loss So Far: {:.6f}'.format(\n",
    "#                 epoch, i * len(sample), len(val_loader.dataset),\n",
    "#                 5. * i / len(val_loader), np.mean(val_losses)))\n",
    "            \n",
    "    print(\"Average Validation Epoch Loss: \", np.mean(val_losses))\n",
    "    print(\"Average Validation Classify Loss: \", np.mean(class_losses))\n",
    "    print(\"Average Validation Regression Loss: \", np.mean(reg_losses))\n",
    "    print(\"\\n\")\n",
    "    global best_val_loss\n",
    "    if np.mean(val_losses) < best_val_loss:\n",
    "        best_val_loss = np.mean(val_losses)\n",
    "        torch.save(model.state_dict(), 'best_val_loss_simple_class_plus_reg.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vr1059/py3.6.3/lib/python3.6/site-packages/ipykernel_launcher.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/home/vr1059/py3.6.3/lib/python3.6/site-packages/ipykernel_launcher.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/home/vr1059/py3.6.3/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if sys.path[0] == '':\n",
      "/home/vr1059/py3.6.3/lib/python3.6/site-packages/ipykernel_launcher.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/2772 (0%)]\tLoss: 15.059708\n",
      "Classify Loss: 4.612013816833496\n",
      "Regression Loss: 20.895387649536133\n",
      "Train Epoch: 0 [2120/2772 (9%)]\tLoss: 8.498049\n",
      "Classify Loss: 4.247972380031239\n",
      "Regression Loss: 14.240845680236816\n",
      "\n",
      "Average Train Epoch Loss:  11.36839519847523\n",
      "Average Validation Epoch Loss:  8.238448143005371\n",
      "Average Validation Classify Loss:  4.1286139488220215\n",
      "Average Validation Regression Loss:  8.21966814994812\n",
      "\n",
      "\n",
      "Train Epoch: 1 [0/2772 (0%)]\tLoss: 7.847879\n",
      "Classify Loss: 3.809628486633301\n",
      "Regression Loss: 8.076501846313477\n",
      "Train Epoch: 1 [2120/2772 (9%)]\tLoss: 5.867127\n",
      "Classify Loss: 3.5708824504505503\n",
      "Regression Loss: 6.086693113500422\n",
      "\n",
      "Average Train Epoch Loss:  6.614229028875178\n",
      "Average Validation Epoch Loss:  5.0261335372924805\n",
      "Average Validation Classify Loss:  3.770180106163025\n",
      "Average Validation Regression Loss:  2.511906683444977\n",
      "\n",
      "\n",
      "Train Epoch: 2 [0/2772 (0%)]\tLoss: 5.482279\n",
      "Classify Loss: 3.3012447357177734\n",
      "Regression Loss: 4.362068176269531\n",
      "Train Epoch: 2 [2120/2772 (9%)]\tLoss: 4.719361\n",
      "Classify Loss: 3.048364357514815\n",
      "Regression Loss: 3.9813862930644643\n",
      "\n",
      "Average Train Epoch Loss:  5.039057558233088\n",
      "Average Validation Epoch Loss:  4.862818717956543\n",
      "Average Validation Classify Loss:  3.615710496902466\n",
      "Average Validation Regression Loss:  2.4942163825035095\n",
      "\n",
      "\n",
      "Train Epoch: 3 [0/2772 (0%)]\tLoss: 4.446039\n",
      "Classify Loss: 2.699643611907959\n",
      "Regression Loss: 3.492790937423706\n",
      "Train Epoch: 3 [2120/2772 (9%)]\tLoss: 4.350548\n",
      "Classify Loss: 2.756376938386397\n",
      "Regression Loss: 3.2487970915707676\n",
      "\n",
      "Average Train Epoch Loss:  4.380775538357821\n",
      "Average Validation Epoch Loss:  14.447431087493896\n",
      "Average Validation Classify Loss:  4.892982721328735\n",
      "Average Validation Regression Loss:  19.10889720916748\n",
      "\n",
      "\n",
      "Train Epoch: 4 [0/2772 (0%)]\tLoss: 3.888444\n",
      "Classify Loss: 2.5200858116149902\n",
      "Regression Loss: 2.736715793609619\n",
      "Train Epoch: 4 [2120/2772 (9%)]\tLoss: 3.543139\n",
      "Classify Loss: 2.591355562210083\n",
      "Regression Loss: 2.682186625220559\n",
      "\n",
      "Average Train Epoch Loss:  3.932448885657571\n",
      "Average Validation Epoch Loss:  8.510460376739502\n",
      "Average Validation Classify Loss:  3.732087731361389\n",
      "Average Validation Regression Loss:  9.556745767593384\n",
      "\n",
      "\n",
      "Train Epoch: 5 [0/2772 (0%)]\tLoss: 3.616050\n",
      "Classify Loss: 2.5417165756225586\n",
      "Regression Loss: 2.148667812347412\n",
      "Train Epoch: 5 [2120/2772 (9%)]\tLoss: 3.504508\n",
      "Classify Loss: 2.4724607901139692\n",
      "Regression Loss: 2.173719514500011\n",
      "\n",
      "Average Train Epoch Loss:  3.5593205365267666\n",
      "Average Validation Epoch Loss:  6.817098140716553\n",
      "Average Validation Classify Loss:  3.5022398233413696\n",
      "Average Validation Regression Loss:  6.629715919494629\n",
      "\n",
      "\n",
      "Train Epoch: 6 [0/2772 (0%)]\tLoss: 3.428870\n",
      "Classify Loss: 2.450315237045288\n",
      "Regression Loss: 1.9571094512939453\n",
      "Train Epoch: 6 [2120/2772 (9%)]\tLoss: 3.090042\n",
      "Classify Loss: 2.388239773837003\n",
      "Regression Loss: 1.8380173661492087\n",
      "\n",
      "Average Train Epoch Loss:  3.307248440655795\n",
      "Average Validation Epoch Loss:  3.8164142370224\n",
      "Average Validation Classify Loss:  3.0454365015029907\n",
      "Average Validation Regression Loss:  1.5419556498527527\n",
      "\n",
      "\n",
      "Train Epoch: 7 [0/2772 (0%)]\tLoss: 2.811040\n",
      "Classify Loss: 2.1952731609344482\n",
      "Regression Loss: 1.2315332889556885\n",
      "Train Epoch: 7 [2120/2772 (9%)]\tLoss: 2.985574\n",
      "Classify Loss: 2.3014891147613525\n",
      "Regression Loss: 1.5841312950307673\n",
      "\n",
      "Average Train Epoch Loss:  3.0935547785325483\n",
      "Average Validation Epoch Loss:  4.177158951759338\n",
      "Average Validation Classify Loss:  3.001819610595703\n",
      "Average Validation Regression Loss:  2.3506785333156586\n",
      "\n",
      "\n",
      "Train Epoch: 8 [0/2772 (0%)]\tLoss: 3.131383\n",
      "Classify Loss: 2.301893472671509\n",
      "Regression Loss: 1.6589791774749756\n",
      "Train Epoch: 8 [2120/2772 (9%)]\tLoss: 2.710030\n",
      "Classify Loss: 2.2065081379630347\n",
      "Regression Loss: 1.357298493385315\n",
      "\n",
      "Average Train Epoch Loss:  2.885157411748713\n",
      "Average Validation Epoch Loss:  4.2619487047195435\n",
      "Average Validation Classify Loss:  3.022205352783203\n",
      "Average Validation Regression Loss:  2.4794867038726807\n",
      "\n",
      "\n",
      "Train Epoch: 9 [0/2772 (0%)]\tLoss: 2.788468\n",
      "Classify Loss: 2.1380929946899414\n",
      "Regression Loss: 1.3007501363754272\n",
      "Train Epoch: 9 [2120/2772 (9%)]\tLoss: 2.616416\n",
      "Classify Loss: 2.0949678962880913\n",
      "Regression Loss: 1.1487772302194075\n",
      "\n",
      "Average Train Epoch Loss:  2.669356519525701\n",
      "Average Validation Epoch Loss:  3.5515663623809814\n",
      "Average Validation Classify Loss:  2.8234344720840454\n",
      "Average Validation Regression Loss:  1.4562637507915497\n",
      "\n",
      "\n",
      "Train Epoch: 10 [0/2772 (0%)]\tLoss: 2.520512\n",
      "Classify Loss: 1.986708641052246\n",
      "Regression Loss: 1.0676069259643555\n",
      "Train Epoch: 10 [2120/2772 (9%)]\tLoss: 2.791429\n",
      "Classify Loss: 2.0171379934657705\n",
      "Regression Loss: 1.123592111197385\n",
      "\n",
      "Average Train Epoch Loss:  2.5789340409365566\n",
      "Average Validation Epoch Loss:  3.705601930618286\n",
      "Average Validation Classify Loss:  3.01885187625885\n",
      "Average Validation Regression Loss:  1.3735001683235168\n",
      "\n",
      "\n",
      "Train Epoch: 11 [0/2772 (0%)]\tLoss: 2.461069\n",
      "Classify Loss: 1.97568941116333\n",
      "Regression Loss: 0.9707594513893127\n",
      "Train Epoch: 11 [2120/2772 (9%)]\tLoss: 2.489542\n",
      "Classify Loss: 1.9418260292573408\n",
      "Regression Loss: 0.9364763823422518\n",
      "\n",
      "Average Train Epoch Loss:  2.4100642421028833\n",
      "Average Validation Epoch Loss:  3.6312503814697266\n",
      "Average Validation Classify Loss:  2.8152624368667603\n",
      "Average Validation Regression Loss:  1.6319758296012878\n",
      "\n",
      "\n",
      "Train Epoch: 12 [0/2772 (0%)]\tLoss: 2.416084\n",
      "Classify Loss: 1.9507416486740112\n",
      "Regression Loss: 0.9306840300559998\n",
      "Train Epoch: 12 [2120/2772 (9%)]\tLoss: 2.070600\n",
      "Classify Loss: 1.8708819150924683\n",
      "Regression Loss: 0.8612145510586825\n",
      "\n",
      "Average Train Epoch Loss:  2.3014891797846015\n",
      "Average Validation Epoch Loss:  3.6061758995056152\n",
      "Average Validation Classify Loss:  2.885951280593872\n",
      "Average Validation Regression Loss:  1.4404491484165192\n",
      "\n",
      "\n",
      "Train Epoch: 13 [0/2772 (0%)]\tLoss: 1.968419\n",
      "Classify Loss: 1.687468409538269\n",
      "Regression Loss: 0.5619003772735596\n",
      "Train Epoch: 13 [2120/2772 (9%)]\tLoss: 2.262692\n",
      "Classify Loss: 1.8023305264386265\n",
      "Regression Loss: 0.7639754739674655\n",
      "\n",
      "Average Train Epoch Loss:  2.184318282387473\n",
      "Average Validation Epoch Loss:  3.5863581895828247\n",
      "Average Validation Classify Loss:  2.875869631767273\n",
      "Average Validation Regression Loss:  1.4209770113229752\n",
      "\n",
      "\n",
      "Train Epoch: 14 [0/2772 (0%)]\tLoss: 1.825009\n",
      "Classify Loss: 1.6223692893981934\n",
      "Regression Loss: 0.4052792489528656\n",
      "Train Epoch: 14 [2120/2772 (9%)]\tLoss: 2.128982\n",
      "Classify Loss: 1.7428601655093106\n",
      "Regression Loss: 0.7647377442229878\n",
      "\n",
      "Average Train Epoch Loss:  2.1252290335568516\n",
      "Average Validation Epoch Loss:  3.5304667949676514\n",
      "Average Validation Classify Loss:  2.816029906272888\n",
      "Average Validation Regression Loss:  1.4288738369941711\n",
      "\n",
      "\n",
      "Train Epoch: 15 [0/2772 (0%)]\tLoss: 2.060992\n",
      "Classify Loss: 1.6866929531097412\n",
      "Regression Loss: 0.7485978007316589\n",
      "Train Epoch: 15 [2120/2772 (9%)]\tLoss: 2.039215\n",
      "Classify Loss: 1.6801658435301348\n",
      "Regression Loss: 0.7308026010339911\n",
      "\n",
      "Average Train Epoch Loss:  2.045567133209922\n",
      "Average Validation Epoch Loss:  3.641047954559326\n",
      "Average Validation Classify Loss:  2.9338458776474\n",
      "Average Validation Regression Loss:  1.414404034614563\n",
      "\n",
      "\n",
      "Train Epoch: 16 [0/2772 (0%)]\tLoss: 1.873376\n",
      "Classify Loss: 1.578168272972107\n",
      "Regression Loss: 0.5904151201248169\n",
      "Train Epoch: 16 [2120/2772 (9%)]\tLoss: 1.947784\n",
      "Classify Loss: 1.6192625219171697\n",
      "Regression Loss: 0.6058044379407709\n",
      "\n",
      "Average Train Epoch Loss:  1.9221647544340654\n",
      "Average Validation Epoch Loss:  3.8096505403518677\n",
      "Average Validation Classify Loss:  3.100183606147766\n",
      "Average Validation Regression Loss:  1.4189340025186539\n",
      "\n",
      "\n",
      "Train Epoch: 17 [0/2772 (0%)]\tLoss: 2.139441\n",
      "Classify Loss: 1.7971512079238892\n",
      "Regression Loss: 0.6845804452896118\n",
      "Train Epoch: 17 [2120/2772 (9%)]\tLoss: 1.864676\n",
      "Classify Loss: 1.5541559024290605\n",
      "Regression Loss: 0.597976183349436\n",
      "\n",
      "Average Train Epoch Loss:  1.8531439954584294\n",
      "Average Validation Epoch Loss:  3.6385239362716675\n",
      "Average Validation Classify Loss:  2.954504132270813\n",
      "Average Validation Regression Loss:  1.3680396676063538\n",
      "\n",
      "\n",
      "Train Epoch: 18 [0/2772 (0%)]\tLoss: 1.809912\n",
      "Classify Loss: 1.5193591117858887\n",
      "Regression Loss: 0.5811061263084412\n",
      "Train Epoch: 18 [2120/2772 (9%)]\tLoss: 1.882067\n",
      "Classify Loss: 1.4852091940966519\n",
      "Regression Loss: 0.6004468067125841\n",
      "\n",
      "Average Train Epoch Loss:  1.7854326096448032\n",
      "Average Validation Epoch Loss:  3.4076638221740723\n",
      "Average Validation Classify Loss:  2.7365397214889526\n",
      "Average Validation Regression Loss:  1.3422482013702393\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 19 [0/2772 (0%)]\tLoss: 1.886814\n",
      "Classify Loss: 1.5008352994918823\n",
      "Regression Loss: 0.7719571590423584\n",
      "Train Epoch: 19 [2120/2772 (9%)]\tLoss: 1.798460\n",
      "Classify Loss: 1.4472281824458728\n",
      "Regression Loss: 0.6206235018643466\n",
      "\n",
      "Average Train Epoch Loss:  1.7575399225408381\n",
      "Average Validation Epoch Loss:  3.4124162197113037\n",
      "Average Validation Classify Loss:  2.743872046470642\n",
      "Average Validation Regression Loss:  1.3370881974697113\n",
      "\n",
      "\n",
      "Train Epoch: 20 [0/2772 (0%)]\tLoss: 1.489144\n",
      "Classify Loss: 1.2741910219192505\n",
      "Regression Loss: 0.42990541458129883\n",
      "Train Epoch: 20 [2120/2772 (9%)]\tLoss: 1.812963\n",
      "Classify Loss: 1.3988181460987439\n",
      "Regression Loss: 0.5935134752230211\n",
      "\n",
      "Average Train Epoch Loss:  1.6955748796463013\n",
      "Average Validation Epoch Loss:  3.567169189453125\n",
      "Average Validation Classify Loss:  2.8873215913772583\n",
      "Average Validation Regression Loss:  1.3596952557563782\n",
      "\n",
      "\n",
      "Train Epoch: 21 [0/2772 (0%)]\tLoss: 1.744775\n",
      "Classify Loss: 1.4380162954330444\n",
      "Regression Loss: 0.6135178804397583\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-dbcdcf9950ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m40\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-b0cb1e102040>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mclass_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mreg_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroad_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfront_right\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfront_left\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/py3.6.3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/py3.6.3/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/py3.6.3/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Self-Driving/data_helper.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0mdata_entries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mannotation_dataframe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mannotation_dataframe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'scene'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mscene_id\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mannotation_dataframe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sample'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0msample_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m         \u001b[0mcorners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_entries\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fl_x'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fr_x'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'bl_x'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'br_x'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fl_y'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fr_y'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'bl_y'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'br_y'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0mcategories\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_entries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategory_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/share/apps/python3/3.6.3/intel/lib/python3.6/site-packages/pandas-0.22.0-py3.6-linux-x86_64.egg/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2131\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2132\u001b[0m             \u001b[0;31m# either boolean or fancy integer index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2133\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2134\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2135\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/share/apps/python3/3.6.3/intel/lib/python3.6/site-packages/pandas-0.22.0-py3.6-linux-x86_64.egg/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_array\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2176\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2177\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2178\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/share/apps/python3/3.6.3/intel/lib/python3.6/site-packages/pandas-0.22.0-py3.6-linux-x86_64.egg/pandas/core/generic.py\u001b[0m in \u001b[0;36m_take\u001b[0;34m(self, indices, axis, convert, is_copy)\u001b[0m\n\u001b[1;32m   2148\u001b[0m         new_data = self._data.take(indices,\n\u001b[1;32m   2149\u001b[0m                                    \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_block_manager_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2150\u001b[0;31m                                    verify=True)\n\u001b[0m\u001b[1;32m   2151\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/share/apps/python3/3.6.3/intel/lib/python3.6/site-packages/pandas-0.22.0-py3.6-linux-x86_64.egg/pandas/core/internals.py\u001b[0m in \u001b[0;36mtake\u001b[0;34m(self, indexer, axis, verify, convert)\u001b[0m\n\u001b[1;32m   4262\u001b[0m         \u001b[0mnew_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4263\u001b[0m         return self.reindex_indexer(new_axis=new_labels, indexer=indexer,\n\u001b[0;32m-> 4264\u001b[0;31m                                     axis=axis, allow_dups=True)\n\u001b[0m\u001b[1;32m   4265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4266\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlsuffix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrsuffix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/share/apps/python3/3.6.3/intel/lib/python3.6/site-packages/pandas-0.22.0-py3.6-linux-x86_64.egg/pandas/core/internals.py\u001b[0m in \u001b[0;36mreindex_indexer\u001b[0;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy)\u001b[0m\n\u001b[1;32m   4144\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4145\u001b[0m             new_blocks = self._slice_take_blocks_ax0(indexer,\n\u001b[0;32m-> 4146\u001b[0;31m                                                      fill_tuple=(fill_value,))\n\u001b[0m\u001b[1;32m   4147\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4148\u001b[0m             new_blocks = [blk.take_nd(indexer, axis=axis, fill_tuple=(\n",
      "\u001b[0;32m/share/apps/python3/3.6.3/intel/lib/python3.6/site-packages/pandas-0.22.0-py3.6-linux-x86_64.egg/pandas/core/internals.py\u001b[0m in \u001b[0;36m_slice_take_blocks_ax0\u001b[0;34m(self, slice_or_indexer, fill_tuple)\u001b[0m\n\u001b[1;32m   4224\u001b[0m                     blocks.append(blk.take_nd(blklocs[mgr_locs.indexer],\n\u001b[1;32m   4225\u001b[0m                                               \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_mgr_locs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4226\u001b[0;31m                                               fill_tuple=None))\n\u001b[0m\u001b[1;32m   4227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4228\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/share/apps/python3/3.6.3/intel/lib/python3.6/site-packages/pandas-0.22.0-py3.6-linux-x86_64.egg/pandas/core/internals.py\u001b[0m in \u001b[0;36mtake_nd\u001b[0;34m(self, indexer, axis, new_mgr_locs, fill_tuple)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mfill_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m             new_values = algos.take_nd(values, indexer, axis=axis,\n\u001b[0;32m-> 1217\u001b[0;31m                                        allow_fill=False)\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m             \u001b[0mfill_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfill_tuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/share/apps/python3/3.6.3/intel/lib/python3.6/site-packages/pandas-0.22.0-py3.6-linux-x86_64.egg/pandas/core/algorithms.py\u001b[0m in \u001b[0;36mtake_nd\u001b[0;34m(arr, indexer, axis, out, fill_value, mask_info, allow_fill)\u001b[0m\n\u001b[1;32m   1380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1381\u001b[0m     func = _get_take_nd_function(arr.ndim, arr.dtype, out.dtype, axis=axis,\n\u001b[0;32m-> 1382\u001b[0;31m                                  mask_info=mask_info)\n\u001b[0m\u001b[1;32m   1383\u001b[0m     \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/share/apps/python3/3.6.3/intel/lib/python3.6/site-packages/pandas-0.22.0-py3.6-linux-x86_64.egg/pandas/core/algorithms.py\u001b[0m in \u001b[0;36m_get_take_nd_function\u001b[0;34m(ndim, arr_dtype, out_dtype, axis, mask_info)\u001b[0m\n\u001b[1;32m   1254\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_get_take_nd_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1255\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mndim\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1256\u001b[0;31m         \u001b[0mtup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0marr_dtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_dtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1257\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1258\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_take_1d_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/py3.6.3/lib/python3.6/site-packages/numpy/core/_dtype.py\u001b[0m in \u001b[0;36m_name_get\u001b[0;34m(dtype)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m     \u001b[0;31m# append bit counts to str, unicode, and void\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missubdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflexible\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_isunsized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m         \u001b[0mname\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitemsize\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/py3.6.3/lib/python3.6/site-packages/numpy/core/numerictypes.py\u001b[0m in \u001b[0;36missubdtype\u001b[0;34m(arg1, arg2)\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m \u001b[0;34m@\u001b[0m\u001b[0mset_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'numpy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    366\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0missubdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m     \"\"\"\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 40\n",
    "for epoch in range(epochs):\n",
    "    train()\n",
    "    val()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.28 lowest val loss so far, cross entropy\n",
    "# I want to try learning classification and regression simultaneously\n",
    "# Actually, I want to try a counting network. \n",
    "# Count how many cars it can see. Classification. \n",
    "\n",
    "# 2.23 (epoch 14) Trying to add RandomAffine, see if lowest classify loss goes down. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification + Regression\n",
    "# Best combined loss: 3.12 (total), 2.46 classify, 1.33 regress\n",
    "\n",
    "# Trying RandomAffine(10) as well. \n",
    "# Best combined loss: 3.40 (total), 2.73 classify, 1.34 regress. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
