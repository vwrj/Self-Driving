{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.rcParams['figure.figsize'] = [5, 5]\n",
    "matplotlib.rcParams['figure.dpi'] = 200\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torch.optim as optim \n",
    "\n",
    "from data_helper import UnlabeledDataset, LabeledDataset\n",
    "from helper import collate_fn, draw_box\n",
    "import resnet_no_fc\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "# Threat score for road detection\n",
    "from helper import compute_ats_bounding_boxes, compute_ts_road_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0);\n",
    "\n",
    "cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image folder\n",
    "image_folder = '/scratch/brs426/data'\n",
    "annotation_csv = '/scratch/brs426/data/annotation.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labeled_scene_index = np.arange(106, 132)\n",
    "val_labeled_scene_index = np.arange(132, 134)\n",
    "test_labeled_scene_index = np.arange(132, 134)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segmentation_collate_fn(batch):\n",
    "    BLOCK_SIZE = 5\n",
    "    road_maps = []\n",
    "    road_bins = []\n",
    "    images = []\n",
    "    for x in batch:\n",
    "        \n",
    "        grid = []\n",
    "        # Collect six images for this sample. \n",
    "        six_images = []\n",
    "        for i in range(6):\n",
    "            six_images.append(torch.as_tensor(x[0][i]))\n",
    "        \n",
    "        # Get road_image and cast it to float\n",
    "        road_image = torch.as_tensor(x[2])\n",
    "        road_maps.append(road_image)\n",
    "        road_image = road_image.float()\n",
    "        \n",
    "        for x in range(0, 800, BLOCK_SIZE):\n",
    "            for y in range(0, 800, BLOCK_SIZE):\n",
    "                block = road_image[x:x+BLOCK_SIZE, y:y+BLOCK_SIZE]\n",
    "                score = torch.sum(block).item()\n",
    "                # If more than have the pixels are 1, classify as road\n",
    "                if score > (BLOCK_SIZE**2) / 2:\n",
    "                    grid.append(1.0)\n",
    "                else:\n",
    "                    grid.append(0.0)\n",
    "            \n",
    "        images.append(torch.stack(six_images))\n",
    "                \n",
    "        road_bins.append(torch.as_tensor(grid))\n",
    "                \n",
    "    boom = torch.stack(images), torch.stack(road_bins), torch.stack(road_maps)\n",
    "    return boom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = torchvision.transforms.ToTensor()\n",
    "aug_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.RandomApply([\n",
    "        torchvision.transforms.ColorJitter(brightness = 0.5, contrast = 0.5, saturation = 0.4, hue = (-0.5, 0.5)),\n",
    "        torchvision.transforms.Grayscale(3),\n",
    "#         transforms.RandomAffine(3),\n",
    "    ]),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = torchvision.transforms.ToTensor()\n",
    "\n",
    "labeled_trainset = LabeledDataset(image_folder=image_folder,\n",
    "                                  annotation_file=annotation_csv,\n",
    "                                  scene_index=train_labeled_scene_index,\n",
    "                                  transform=aug_transform,\n",
    "                                  extra_info=True\n",
    "                                 )\n",
    "trainloader = torch.utils.data.DataLoader(labeled_trainset, batch_size=16, shuffle=True, num_workers=10, collate_fn=segmentation_collate_fn)\n",
    "\n",
    "labeled_valset = LabeledDataset(image_folder=image_folder,\n",
    "                                  annotation_file=annotation_csv,\n",
    "                                  scene_index=val_labeled_scene_index,\n",
    "                                  transform=transform,\n",
    "                                  extra_info=True\n",
    "                                 )\n",
    "valloader = torch.utils.data.DataLoader(labeled_valset, batch_size=1, shuffle=True, num_workers=2, collate_fn=segmentation_collate_fn)\n",
    "\n",
    "labeled_testset = LabeledDataset(image_folder=image_folder,\n",
    "                                  annotation_file=annotation_csv,\n",
    "                                  scene_index=test_labeled_scene_index,\n",
    "                                  transform=transform,\n",
    "                                  extra_info=True\n",
    "                                 )\n",
    "testloader = torch.utils.data.DataLoader(labeled_testset, batch_size=2, shuffle=True, num_workers=2, collate_fn=segmentation_collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starting Segmentation Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        \n",
    "        self.encoder = torchvision.models.resnet50()\n",
    "        self.encoder.fc = nn.Identity()\n",
    "        self.concat_dim = 200 * 6\n",
    "        \n",
    "        self.compress = nn.Sequential(OrderedDict([\n",
    "            ('linear0', nn.Linear(2048, 200)),\n",
    "            ('drop', nn.Dropout(p = 0.5)),\n",
    "            ('relu', nn.ReLU()),\n",
    "        ]))\n",
    "        \n",
    "        self.segmentation = nn.Sequential(OrderedDict([\n",
    "            ('linear1', nn.Linear(self.concat_dim, 25600)),\n",
    "            ('sigmoid', nn.Sigmoid())\n",
    "        ]))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        num_images = x.shape[1]\n",
    "        channels = x.shape[2]\n",
    "        height = x.shape[3]\n",
    "        width = x.shape[4]\n",
    "        \n",
    "        # Reshape to feed in images\n",
    "        x = x.reshape(-1, channels, height, width)\n",
    "        \n",
    "        x = self.encoder(x)\n",
    "        x = self.compress(x)\n",
    "        x = x.view(-1, self.concat_dim)\n",
    "        return self.segmentation(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train logic, return average loss over training set after each epoch\n",
    "def train(model, device, train_loader, optimizer, epoch, log_file_path, log_interval = 250):\n",
    "    # Set model to training mode\n",
    "    model.train()\n",
    "    \n",
    "    # Number correct for accuracy\n",
    "    num_correct = 0\n",
    "    \n",
    "    # Train loss\n",
    "    train_loss = 0\n",
    "    \n",
    "    f = open(log_file_path, \"a+\")\n",
    "    # Loop through examples\n",
    "    for batch_idx, (images, bins, road_map) in enumerate(train_loader):\n",
    "        \n",
    "        \n",
    "        # Send data and target to device\n",
    "        data, target = images.to(device), bins.to(device)\n",
    "        \n",
    "        # Zero out optimizer\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Pass data through model - right now only segmentation\n",
    "        output = model(data)\n",
    "        # Should be batch_size X 800 X 800\n",
    "        output = output.squeeze()\n",
    "        \n",
    "        # Compute the loss\n",
    "        loss = F.binary_cross_entropy(output, target)\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        # Backpropagate loss\n",
    "        loss.backward()\n",
    "        \n",
    "        # Make a step with the optimizer\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Print loss (uncomment lines below once implemented)\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "            f.write('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\n'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "    \n",
    "    \n",
    "    # Average train loss\n",
    "    average_train_loss = train_loss / len(train_loader)\n",
    "    # Print loss (uncomment lines below once implemented)\n",
    "    print('\\nTrain set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        average_train_loss, num_correct, len(train_loader.dataset),\n",
    "        100. * num_correct / len(train_loader.dataset)))\n",
    "    f.write('\\nTrain set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        average_train_loss, num_correct, len(train_loader.dataset),\n",
    "        100. * num_correct / len(train_loader.dataset)))\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_from_bins(bins, block_size, threshold):\n",
    "    road_map = torch.zeros((800, 800))\n",
    "    idx = 0\n",
    "    for x in range(0, 800, block_size):\n",
    "        for y in range(0, 800, block_size):\n",
    "            road_map[x:x+block_size, y:y+block_size] = bins[idx]\n",
    "            idx += 1\n",
    "    return road_map > threshold\n",
    "\n",
    "\n",
    "# Define test method\n",
    "def test(model, device, test_loader, log_file_path):\n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "    # Variable for the total loss \n",
    "    test_loss = 0\n",
    "    # Counter for the correct predictions\n",
    "    num_correct = 0\n",
    "    \n",
    "#     thresholds = [0.42]\n",
    "    \n",
    "#     threat_scores = torch.zeros(1)\n",
    "    \n",
    "    f = open(log_file_path, \"a+\")\n",
    "    # don't need autograd for eval\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (images, bins, road_map) in enumerate(test_loader):\n",
    "\n",
    "            # Send data and target to device\n",
    "            data, target= images.to(device), bins.to(device)\n",
    "\n",
    "            # Pass data through model - right now only segmentation\n",
    "            output = model(data)\n",
    "            # Should be batch_size X 6400\n",
    "\n",
    "            # Compute the loss\n",
    "            loss = F.binary_cross_entropy(output, target)\n",
    "            test_loss += loss.item()\n",
    "            \n",
    "            # Now squeeze for reconstruction\n",
    "#             output = output.squeeze()\n",
    "            \n",
    "            # Compute threat score at 4 different thresholds\n",
    "#              for idx in range(len(thresholds)):\n",
    "#                 reconstructed_road_map = reconstruct_from_bins(output, 5, thresholds[idx]).cpu()\n",
    "#                 ts_road_map = compute_ts_road_map(reconstructed_road_map, road_map)\n",
    "#                 threat_scores[idx] += ts_road_map\n",
    "         \n",
    "    # Compute the average test_loss\n",
    "    # avg_test_loss = TODO\n",
    "    avg_test_loss = test_loss / len(test_loader)\n",
    "    \n",
    "    # Compute average threat scores\n",
    "#     avg_threat_scores = threat_scores / len(test_loader)\n",
    "    \n",
    "#     print('\\Threat scores: \\t {}:{}\\n'.format(thresholds[0], avg_threat_scores[0]))\n",
    "    # Print loss (uncomment lines below once implemented)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        avg_test_loss, num_correct, len(test_loader.dataset),\n",
    "        100. * num_correct / len(test_loader.dataset)))\n",
    "    \n",
    "#     f.write('\\Threat scores: \\t {}:{}\\n'.format(thresholds[0], avg_threat_scores[0]))\n",
    "    f.write('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        avg_test_loss, num_correct, len(test_loader.dataset),\n",
    "        100. * num_correct / len(test_loader.dataset)))\n",
    "    f.close()\n",
    "    \n",
    "    return avg_test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segmentation model\n",
    "model = SimpleModel().to(device)\n",
    "# Optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=2e-4)\n",
    "# Scheduler\n",
    "# scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', factor=0.25, patience=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/3276 (0%)]\tLoss: 0.709031\n",
      "\n",
      "Train set: Average loss: 0.4101, Accuracy: 0/3276 (0%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.5740, Accuracy: 0/252 (0%)\n",
      "\n",
      "Train Epoch: 2 [0/3276 (0%)]\tLoss: 0.396442\n",
      "\n",
      "Train set: Average loss: 0.3447, Accuracy: 0/3276 (0%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.3608, Accuracy: 0/252 (0%)\n",
      "\n",
      "Train Epoch: 3 [0/3276 (0%)]\tLoss: 0.328270\n",
      "\n",
      "Train set: Average loss: 0.3026, Accuracy: 0/3276 (0%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.3533, Accuracy: 0/252 (0%)\n",
      "\n",
      "Train Epoch: 4 [0/3276 (0%)]\tLoss: 0.281184\n",
      "\n",
      "Train set: Average loss: 0.2754, Accuracy: 0/3276 (0%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.3694, Accuracy: 0/252 (0%)\n",
      "\n",
      "Train Epoch: 5 [0/3276 (0%)]\tLoss: 0.290910\n",
      "\n",
      "Train set: Average loss: 0.2570, Accuracy: 0/3276 (0%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.3162, Accuracy: 0/252 (0%)\n",
      "\n",
      "Train Epoch: 6 [0/3276 (0%)]\tLoss: 0.272999\n",
      "\n",
      "Train set: Average loss: 0.2427, Accuracy: 0/3276 (0%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.2849, Accuracy: 0/252 (0%)\n",
      "\n",
      "Train Epoch: 7 [0/3276 (0%)]\tLoss: 0.220619\n",
      "\n",
      "Train set: Average loss: 0.2301, Accuracy: 0/3276 (0%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.2823, Accuracy: 0/252 (0%)\n",
      "\n",
      "Train Epoch: 8 [0/3276 (0%)]\tLoss: 0.230194\n",
      "\n",
      "Train set: Average loss: 0.2179, Accuracy: 0/3276 (0%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.3097, Accuracy: 0/252 (0%)\n",
      "\n",
      "Train Epoch: 9 [0/3276 (0%)]\tLoss: 0.193672\n",
      "\n",
      "Train set: Average loss: 0.2060, Accuracy: 0/3276 (0%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.2617, Accuracy: 0/252 (0%)\n",
      "\n",
      "Train Epoch: 10 [0/3276 (0%)]\tLoss: 0.176472\n",
      "\n",
      "Train set: Average loss: 0.1963, Accuracy: 0/3276 (0%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.2714, Accuracy: 0/252 (0%)\n",
      "\n",
      "Train Epoch: 11 [0/3276 (0%)]\tLoss: 0.174470\n",
      "\n",
      "Train set: Average loss: 0.1872, Accuracy: 0/3276 (0%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.2431, Accuracy: 0/252 (0%)\n",
      "\n",
      "Train Epoch: 12 [0/3276 (0%)]\tLoss: 0.202961\n",
      "\n",
      "Train set: Average loss: 0.1795, Accuracy: 0/3276 (0%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.2831, Accuracy: 0/252 (0%)\n",
      "\n",
      "Train Epoch: 13 [0/3276 (0%)]\tLoss: 0.203254\n",
      "\n",
      "Train set: Average loss: 0.1725, Accuracy: 0/3276 (0%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.2401, Accuracy: 0/252 (0%)\n",
      "\n",
      "Train Epoch: 14 [0/3276 (0%)]\tLoss: 0.176757\n",
      "\n",
      "Train set: Average loss: 0.1656, Accuracy: 0/3276 (0%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.2552, Accuracy: 0/252 (0%)\n",
      "\n",
      "Train Epoch: 15 [0/3276 (0%)]\tLoss: 0.209612\n",
      "\n",
      "Train set: Average loss: 0.1587, Accuracy: 0/3276 (0%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.2473, Accuracy: 0/252 (0%)\n",
      "\n",
      "Train Epoch: 16 [0/3276 (0%)]\tLoss: 0.171521\n",
      "\n",
      "Train set: Average loss: 0.1537, Accuracy: 0/3276 (0%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.2589, Accuracy: 0/252 (0%)\n",
      "\n",
      "Train Epoch: 17 [0/3276 (0%)]\tLoss: 0.135337\n",
      "\n",
      "Train set: Average loss: 0.1498, Accuracy: 0/3276 (0%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.2866, Accuracy: 0/252 (0%)\n",
      "\n",
      "Train Epoch: 18 [0/3276 (0%)]\tLoss: 0.147160\n",
      "\n",
      "Train set: Average loss: 0.1444, Accuracy: 0/3276 (0%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.2479, Accuracy: 0/252 (0%)\n",
      "\n",
      "Train Epoch: 19 [0/3276 (0%)]\tLoss: 0.180121\n",
      "\n",
      "Train set: Average loss: 0.1406, Accuracy: 0/3276 (0%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.2434, Accuracy: 0/252 (0%)\n",
      "\n",
      "Train Epoch: 20 [0/3276 (0%)]\tLoss: 0.099562\n",
      "\n",
      "Train set: Average loss: 0.1377, Accuracy: 0/3276 (0%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.2524, Accuracy: 0/252 (0%)\n",
      "\n",
      "Train Epoch: 21 [0/3276 (0%)]\tLoss: 0.160055\n",
      "\n",
      "Train set: Average loss: 0.1347, Accuracy: 0/3276 (0%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.3059, Accuracy: 0/252 (0%)\n",
      "\n",
      "Train Epoch: 22 [0/3276 (0%)]\tLoss: 0.109348\n",
      "\n",
      "Train set: Average loss: 0.1318, Accuracy: 0/3276 (0%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.2211, Accuracy: 0/252 (0%)\n",
      "\n",
      "Train Epoch: 23 [0/3276 (0%)]\tLoss: 0.130393\n",
      "\n",
      "Train set: Average loss: 0.1277, Accuracy: 0/3276 (0%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.2566, Accuracy: 0/252 (0%)\n",
      "\n",
      "Train Epoch: 24 [0/3276 (0%)]\tLoss: 0.123901\n"
     ]
    }
   ],
   "source": [
    "f = \"/scratch/brs426/ben_models/simple_model_block_size_25_test_threat_alone.log\"\n",
    "best_val_loss = 100\n",
    "save_path = \"/scratch/brs426/ben_models/simple_model_block_size_25_test_threat_alone.p\"\n",
    "epochs = 40\n",
    "for epoch in range(1, epochs + 1):\n",
    "    # Train model\n",
    "    loss = train(model, device, trainloader, optimizer, epoch, f)\n",
    "    val_loss = test(model, device, valloader, f)\n",
    "#     scheduler.step(val_threat)\n",
    "    #Save model\n",
    "    if val_loss < best_val_loss:\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "        best_val_loss = val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Threat Score Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold 0.4: tensor([0.8311])\n"
     ]
    }
   ],
   "source": [
    "def reconstruct_from_bins(bins, block_size, threshold):\n",
    "    road_map = torch.zeros((800, 800))\n",
    "    idx = 0\n",
    "    for x in range(0, 800, block_size):\n",
    "        for y in range(0, 800, block_size):\n",
    "            road_map[x:x+block_size, y:y+block_size] = bins[idx]\n",
    "            idx += 1\n",
    "    return road_map > threshold\n",
    "\n",
    "# Predicting everything as road\n",
    "model = SimpleModel().to(device)\n",
    "model.load_state_dict(torch.load(\"/scratch/brs426/ben_models/simple_model_block_size_25_test_threat_alone.p\"))\n",
    "model.eval()\n",
    "\n",
    "thresholds = [0.4]\n",
    "\n",
    "threat_scores = torch.zeros(1)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (images, bins, road_map) in enumerate(valloader):\n",
    "\n",
    "        # Send data and target to device\n",
    "        data, target= images.to(device), bins.to(device)\n",
    "\n",
    "        # Pass data through model - right now only segmentation\n",
    "        output = model(data)\n",
    "        # Should be batch_size X 6400\n",
    "\n",
    "#         # Compute the loss\n",
    "#         loss = F.binary_cross_entropy(output, target)\n",
    "#         test_loss += loss.item()\n",
    "\n",
    "        # Now squeeze for reconstruction\n",
    "        output = output.squeeze()\n",
    "\n",
    "        # Compute threat score at 4 different thresholds\n",
    "        for idx in range(len(thresholds)):\n",
    "            reconstructed_road_map = reconstruct_from_bins(output, 25, thresholds[idx]).cpu()\n",
    "            ts_road_map = compute_ts_road_map(reconstructed_road_map, road_map)\n",
    "            threat_scores[idx] += ts_road_map\n",
    "\n",
    "avg_threat_scores = threat_scores / len(valloader)\n",
    "print(\"Threshold 0.4: {}\".format(avg_threat_scores))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
